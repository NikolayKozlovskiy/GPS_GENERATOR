{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to GPS Synth Generator \ud83d\udc63","text":"<p>The project aimed to create a Python codebase for synthetic GPS data generation and also on practice implement some good coding approaches. I would welcome any feedback, contribution, and usage of this code. To better and quicklier grasp the content and the essence of the code I have created GitHub Pages with all relavent information, here is the following sections: </p> <ul> <li>Overview - a description of the core idea of the project and code orchestration</li> <li>Dev Guide - a guidelence for setting up a development environment (production is yet not really relevant for this current state of the project) and contribution block with the rules and possible topics to work on</li> <li>User Manual - a brief explanation of <code>Makefile</code> commands to use once a dev env is ready + output structure of the code results</li> <li>Code Reference - a code documentation</li> <li>Aknowledgement - to melt your hearts</li> <li>LICENSE - let's pretend that it will one day be needed</li> </ul>"},{"location":"LICENSE_DOCS/","title":"License","text":"<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright 2014 Nikolay Kozlovskiy</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"},{"location":"aknowledgement/","title":"Aknowledgements","text":"<p>The concept and initial development of this project began during my internship at Positium. For more details on the project's origins, please see the <code>archive</code> folder, which includes a PDF documentation (useful for understanding the overall logic) and a Jupyter notebook (not for execution). The evolution of the <code>GPS_GENERATOR</code> was also influenced by my experience at Positium, where I had the opportunity to explore various development practices.</p>"},{"location":"overview/","title":"About GPS Synth \ud83d\uddc2\ufe0f","text":"<p>This Python codebase generates synthetic GPS data based on the properties of a network and users. The code source allows for flexible specification of unique characteristics for a network (e.g., a place of interest) and user parameters (e.g., speed limit).</p> <p>The basic foundation of the approach is as follows:</p> <ul> <li>Each use case is denoted as a profile. For each profile, network and user parameters should be specified</li> <li>Profiles can share the identical network (if network parameters are the same), but will always have a different movement history for their users (meaning that even if users' parameters are the same, the output trajectories will be different)</li> <li>A network is a combination of anchor points/locations and roads/ways that connect locations to each other (essentially, a graph with nodes and edges)</li> <li>All locations are derived from OpenStreetMap's conceptual data model of the physical world using the osmnx library</li> <li>There are three main types of locations: home, work and event (bars, parks, museums, etc.). Event could be either one of the regular locations of a user or random location (amenity) in the area</li> <li>The entire movement history of a user can be described as a consecutive process of stay and movement activities happen in some locations</li> <li>The combination of these two types of activities and the type of locations in which they occur are specified by the plot. Each unique movement plot should automatically produce a new child class of the Parent Class User (e.g., <code>User_employed_walk</code> class in <code>./gps_synth/user/user_employed_walk.py</code>)</li> </ul>"},{"location":"user_manual/","title":"User Manual \ud83e\uddae","text":""},{"location":"user_manual/#brief-navigation","title":"Brief navigation","text":"<p>To enable pre-commit hooks run the <code>pre-commit install</code> command to set up the git hooks integration with <code>.pre-commit-config.yaml</code> file.</p> <p>It is hihly recommended to use Docker environment. If you need to experiment with the code, print out the specific output you can do this in JupyterLab, execute <code>make run_jupyter_lab</code> and go to <code>http://127.0.0.1:8888/lab</code> (the port should not be occupied both in docker and local machine). If you want to run some other 'more custom' commands use docker exec option, make sure your container is running.</p>"},{"location":"user_manual/#output-structure","title":"Output structure","text":"<p>There are three main outputs of the repository, all in parquet format and partitioned: </p> <ol> <li>GPS data with following columns: <code>user_id,timestamp,lon,lat,profile_name</code>; </li> <li>Network data with following columns: <code>element_type,osmid,name,centre_x,centre_y,loc_type,network_name</code> </li> <li>Metadata with the following columns: <code>user_id,home_id,work_id,regular_loc_array,profile_name, network_name</code></li> </ol> <p>Example of the output structure:</p> <pre><code>/output_root\n\u251c\u2500\u2500 gps_data\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 profile_name=profile_name_1\n\u2502   \u2502   \u251c\u2500\u2500 part-{i}[hex].parquet\n\u2502   \u2502   \u2514\u2500\u2500 part-{i}[hex].parquet\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 profile_name=profile_name_2\n\u2502       \u251c\u2500\u2500 part-{i}[hex].parquet\n\u2502       \u2514\u2500\u2500 part-{i}[hex].parquet\n\u2502\n\u251c\u2500\u2500 metadata\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 profile_name=profile_name_1\n\u2502   \u2502   \u251c\u2500\u2500 part-{i}[hex].parquet\n\u2502   \u2502   \u2514\u2500\u2500 part-{i}[hex].parquet\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 profile_name=profile_name_2\n\u2502       \u251c\u2500\u2500 part-{i}[hex].parquet\n\u2502       \u2514\u2500\u2500 part-{i}[hex].parquet\n\u2502\n\u2514\u2500\u2500 network_data\n    \u2502\n    \u2514\u2500\u2500 network_name=network_name_1\n        \u251c\u2500\u2500 part-{i}[hex].parquet\n        \u2514\u2500\u2500 part-{i}[hex].parquet\n</code></pre> <p>P.S. In <code>notebooks/vis_notebook.ipynb</code> there are some approaches implemented to visualise and analyse results.</p>"},{"location":"dev_guide/","title":"Development Guide","text":"<p>This document presents the setup and contribution guides:  </p> <ul> <li>Setup: Section explaining how to install and deploy the software.  </li> <li>Contribution: Section explaining how to contribute to the software.  </li> </ul>"},{"location":"dev_guide/contribution/","title":"Contribution \ud83d\udc8a","text":""},{"location":"dev_guide/contribution/#contribution-guidelines","title":"Contribution guidelines","text":"<ol> <li>Fork the repo</li> <li>Open an issue </li> <li>Create a branch to this issue that originates from the main branch</li> <li>Once issue is resolved, create a PR to the created issue</li> <li>Cross fingers and give yourself deserve praise - the repository administrator(s) will review the PR and hopefully merge it to the main \ud83e\udd1e</li> </ol>"},{"location":"dev_guide/contribution/#issues-to-work-on","title":"Issues to work on","text":"<p>I am arrogant enough to think that this project might be interesting for someone. Below is a list of issues which can make the results more humanlike, diverse, and efficient.</p> <ol> <li> <p>Make movements more realistic:</p> <ul> <li>The path between the location and its nearest node can intersect buildings or water bodies (lakes). A user goes through them, it is not realistic.</li> <li>GPS-like errors in the data (e.g., sudden termination of \u2018acquiring\u2019 data, or some points that do not make sense).</li> </ul> </li> <li> <p>Create more profiles and new User classes:</p> <ul> <li>New places.</li> <li>New OSM tags for anchor points.</li> <li>New modes of transport and their combination.</li> <li>New movement plots.</li> </ul> </li> <li> <p>In terms of growing number of profiles, possible rethinking of orchestration approach.</p> </li> <li>Code optimization (e.g., in <code>get_meaningful_locations()</code>).</li> <li>Testing, benchmarking, trying new config params.</li> <li>More detailed and thorough approach for results' evaluation</li> <li>Just to play around: setting up and running code on Cloud using e.g. Terraform</li> </ol>"},{"location":"dev_guide/setup/","title":"Setup Guide \ud83d\udc77","text":"<p>Both approaches leveraging Poetry, a tool that offers an intelligent and intuitive approach to handle Python dependencies. Important note: Poetry doesn't include Python internally, hence it uses Python somewhere externally e.g. from Docker Image, local machine, etc.</p>"},{"location":"dev_guide/setup/#docker-poetry-makefile","title":"Docker + Poetry + Makefile","text":"<p>Code is executed within a docker container, however, the outcome can also be directed to your host. The commands are wrapped up in Makefile for convenience*</p> <ol> <li>Navigate to a directory you want to run the codebase and store results</li> <li>Clone the repo: <code>git clone https://github.com/NikolayKozlovskiy/GPS_GENERATOR.git</code></li> <li>Move the repo directory e.g. <code>cd GPS_GENERATOR</code></li> <li>Build a docker image called gps_generator: <code>make build_docker_image</code></li> <li>In <code>Makefile</code> correctly specify relative paths for your source directories which then will be used in bind mounts: <code>OUTPUT_DIR</code> and <code>CONFIG</code> (or use default ones)</li> <li>Based on the image create a docker container named the same, which will constatntly run till it is removed: <code>make create_docker_container</code></li> <li>Open a new terminal (a docker container is runing in the first one) and run the <code>main.py</code> script: <code>make run_main_script</code></li> <li>When you no longer need a container, remove it: <code>make remove_docker_container</code></li> </ol> <p>Prerequirements:</p> <ol> <li>Installed Docker</li> </ol> <p>*If <code>make</code> is not available just open Makefile in text editor and run corresponding shell commands in terminal manually</p>"},{"location":"dev_guide/setup/#conda-poetry","title":"Conda + Poetry","text":"<p>The fundamental approach remains unchanged, except that in this scenario, Conda is employed to establish an environment with a specified Python version and now you run scripts not in a container but some machine. Despite this, Poetry retains its responsibility for managing dependencies. What approach to use is a difficulty of having alternatives</p> <ol> <li>Navigate to a directory you want to run the codebase and store results</li> <li>Clone the repo: <code>git clone https://github.com/NikolayKozlovskiy/GPS_GENERATOR.git</code></li> <li>Move to GPS_GENERATOR directory: <code>cd GPS_GENERATOR</code></li> <li>Create python environment with conda, conda is used for downloading python; 3.9 &lt;= python version &lt;= 3.12 because of dependecies' specifics: <code>conda create --name [your_env_name] python=3.10 -y</code></li> <li>Activate python environment: <code>conda activate [your_env_name]</code></li> <li>Install poetry, version - up to you to choose: <code>pip install poetry==1.6.0</code></li> <li>Install other dependencies listed in pyproject.toml, <code>poetry install --with vis,docs</code>, --with vis,docs option specifies that along with core dependencies optional groups called vis and docs should be installed. vis group includes libraries that you may need to analyse and visualise the output results, docs group is useful for generating and managing project documentation, just run <code>poetry install</code> if you don't need these additional groups</li> <li>Run the codebase: <code>python gps_synth/main.py configs/[your_config].yaml</code>*</li> </ol> <p>Prerequirements:</p> <ol> <li>Installed conda, the easiest way is to download Miniconda</li> <li>Installed gdal locally</li> </ol> <p>*You may need to directly specify the python path to GPS_GENERATOR: <code>export PYTHONPATH=/path/to/GPS_GENERATOR folder</code> for MacOs, for other operating systems ask ChatGPT </p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>common<ul> <li>abs_user</li> <li>columns</li> <li>functions</li> </ul> </li> <li>gps_generator<ul> <li>gps_generator</li> </ul> </li> <li>main</li> <li>network<ul> <li>network</li> </ul> </li> <li>user<ul> <li>user_employed_walk</li> </ul> </li> </ul>"},{"location":"reference/main/","title":"main","text":""},{"location":"reference/main/#main.main","title":"<code>main(config_file_path)</code>","text":"<p>Load config, setup logger, initialise GPS_Generator class and run it</p> <p>Parameters:</p> Name Type Description Default <code>config_file_path</code> <code>str</code> <p>Relative path to config file spceified as the second parameter in terminal command</p> required Source code in <code>gps_synth/main.py</code> <pre><code>def main(config_file_path: str) -&gt; None:\n    \"\"\"\n    Load config, setup logger, initialise GPS_Generator class and run it\n\n    Args:\n        config_file_path (str): Relative path to config file spceified as the second parameter in terminal command\n    \"\"\"\n\n    base_dir = os.getcwd()\n\n    with open(str(config_file_path), \"r\", encoding=\"utf-8\") as f_in:\n        config = yaml.safe_load(f_in)\n\n    set_up_logger(config, base_dir)\n\n    logger = logging.getLogger(__name__)\n\n    logger.info(\"Run main.py\")\n\n    GPS_GENERATOR = class_getter(\n        config[\"INIT\"][\"GPS_GENERATOR_PATH\"], config[\"INIT\"][\"GPS_GENERATOR_CLASS\"]\n    )\n\n    GPS_GENERATOR = GPS_GENERATOR(config, base_dir)\n\n    GPS_GENERATOR.run()\n</code></pre>"},{"location":"reference/main/#main.set_up_logger","title":"<code>set_up_logger(config, base_dir)</code>","text":"<p>The function creates a log_dir folder (by appending sub-path to the base/parent path) to store logs and sets up a logger</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>YAML object with all specified config params</p> required <code>base_dir</code> <code>str</code> <p>The string path to GPS_Generator folder</p> required Source code in <code>gps_synth/main.py</code> <pre><code>def set_up_logger(config: Any, base_dir: str) -&gt; None:\n    \"\"\"\n    The function creates a log_dir folder (by appending sub-path to the base/parent path) to store logs\n    and sets up a logger\n\n    Args:\n        config (Any): YAML object with all specified config params\n        base_dir (str): The string path to GPS_Generator folder\n    \"\"\"\n\n    log_dir = os.path.join(base_dir, config[\"LOGGING\"][\"LOG_DIR\"])\n    check_or_create_dir(log_dir)\n\n    log_file_path = os.path.join(\n        log_dir, f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H_%M_%S')}.log\"\n    )\n    logging.getLogger(__name__)\n    logging.basicConfig(\n        format=config[\"LOGGING\"][\"FORMAT\"],\n        handlers=[logging.FileHandler(log_file_path, \"w\"), logging.StreamHandler()],\n        datefmt=config[\"LOGGING\"][\"DATEFMT\"],\n        level=config[\"LOGGING\"][\"LEVEL\"],\n    )\n</code></pre>"},{"location":"reference/common/abs_user/","title":"abs_user","text":"<p>User class is a parent class of all child classes specified in user module <code>gps_synth/user</code>.</p> <p>User class has a combination of concrete and abstract methods:</p> <ul> <li>concrete methods are meant to be called in child classes with super() function.</li> <li>abstract methods are meant to show what methods should be in a child class, but their implementation is a subject of this child class.</li> </ul>"},{"location":"reference/common/abs_user/#common.abs_user.User","title":"<code>User</code>","text":"<p>               Bases: <code>ABC</code></p> Source code in <code>gps_synth/common/abs_user.py</code> <pre><code>class User(ABC):\n    def __init__(self, user_id: int, profile_user_config):\n        self.user_id = user_id\n        self.date_range = pd.date_range(\n            profile_user_config[\"DATE_BEGGINING\"],\n            profile_user_config[\"DATE_END\"],\n            freq=\"d\",\n        )\n        self.radius_buffer_h_w = profile_user_config[\"RADIUS_BUFFER_H_W\"]\n        self.radius_buffer_h_r = profile_user_config[\"RADIUS_BUFFER_H_R\"]\n        self.mean_move_speed_ms = profile_user_config[\"MEAN_MOVE_SPEED_MS\"]\n        self.proximity_to_road = profile_user_config[\"PROXIMITY_TO_ROAD\"]\n\n        self.home_id = None\n        self.work_id = None\n        self.regular_loc_array = None\n\n        self.data_array = []\n\n    def get_random_id_within_buffer(\n        self, center_point: Point, radius_buffer: int, gdf_locations: GeoDataFrame\n    ) -&gt; Union[int, None]:\n        \"\"\"\n        Find a random id of a location which is within a buffer, created around center point with specified distance.\n        A center point should be surronded with some amount of needed locations, otherwise None\n\n        Args:\n            center_point (Point): A point around which create a buffer\n            radius_buffer (int): A radius of a buffer\n            gdf_locations (GeoDataFrame): Locations to filter with condition \"within a buffer\"\n\n        Returns:\n            int: Random id among filtered loctions or None if home anchor is too near to border of a place\n        \"\"\"\n\n        buffer = shapely.buffer(center_point, distance=radius_buffer)\n        index_list = gdf_locations[gdf_locations.within(buffer)].index\n        # TODO: 20 is arbitary threshold, e.g. there could be just a case that a place does not have\n        # some types of locations in many quantaties, think about how logically define this value\n        # and make it as another positional argument\n        if len(index_list) &gt;= 20:\n            random_id = random.choice(gdf_locations[gdf_locations.within(buffer)].index)\n            return random_id\n\n        return None\n\n    def get_meaningful_locations(\n        self,\n        gdf_hw: GeoDataFrame,\n        gdf_event: GeoDataFrame,\n    ) -&gt; None:\n        \"\"\"\n        Create meaningful locations for a user: one home, one work, several regular events,\n        the radius between home and work and home and regular locations are defined in the config\n        The distribution of meaningful locations should follow some distance conditions.\n        Store computed anchors in correponding instance attributes\n\n        Args:\n            gdf_hw (GeoDataFrame): Set of locations of a network to choose from for home and work anchors\n            gdf_event (GeoDataFrame): Set of locations of a network to choose from for regular event anchors\n        \"\"\"\n        # radius_buffer_h_w (int): Radius to create a buffer around home anchor to search for work anchor\n        radius_buffer_h_w = self.radius_buffer_h_w\n        # radius_buffer_h_w (int): Radius to create a buffer around home anchor to search for regular event anchors\n        radius_buffer_h_r = self.radius_buffer_h_r\n\n        home_id = random.randint(0, len(gdf_hw) - 1)\n        home_geometry = gdf_hw.iloc[home_id][\"geometry\"]\n        # TODO: too conditionally nested think about a better approach\n        while True:\n\n            work_id = self.get_random_id_within_buffer(\n                home_geometry, radius_buffer_h_w, gdf_hw\n            )\n            # if there are not many possible work anchor locations around\n            if work_id is None:\n                # change home id\n                home_id = random.randint(0, len(gdf_hw) - 1)\n                home_geometry = gdf_hw.iloc[home_id][\"geometry\"]\n            # if the same just choose another work id, but don't change home anchor\n            elif home_id == work_id:\n                continue\n\n            else:\n                regular_locations_ids = []\n                number_of_regular_locations = random.randint(3, 5)\n                i = 0\n                while i &lt;= number_of_regular_locations:\n                    regular_id = self.get_random_id_within_buffer(\n                        home_geometry, radius_buffer_h_r, gdf_event\n                    )\n\n                    # if there are not many possible regular event anchors around increase search radius\n                    if regular_id is None:\n                        radius_buffer_h_r += 100\n                    # if id is already used, chooses another one\n                    elif (\n                        regular_id in regular_locations_ids\n                        or regular_id == home_id\n                        or regular_id == work_id\n                    ):\n                        continue\n                    else:\n                        regular_locations_ids.append(regular_id)\n                        i += 1\n\n                self.home_id = home_id\n                self.work_id = work_id\n                self.regular_loc_array = regular_locations_ids\n                break\n\n    def get_regular_or_random_loc(\n        self,\n        gdf_event: GeoDataFrame,\n        regular_location_ids: List[int],\n        number_of_events: int,\n    ) -&gt; List[int]:\n        \"\"\"\n        Randomly create a list with specified number of event ids, which could be either from regular event locations or completely accidental\n\n        Args:\n            gdf_event (GeoDataFrame): Set of locations of a network to choose from for regular event anchors\n            regular_location_ids (List[int]): List of regular event locations' ids\n            number_of_events (int): A number of event ids tom create\n\n        Returns:\n            List[int]: List of event ids for a userto visit within a day\n        \"\"\"\n        event_id_list = []\n        while len(event_id_list) &lt; number_of_events:\n            choose_reg_or_random = random.choices(\n                [\"reg\", \"random\"], weights=[0.6, 0.4], k=1\n            )[0]\n            if choose_reg_or_random == \"reg\":\n                event_id = random.choice(regular_location_ids)\n            else:\n                event_id = random.randint(0, len(gdf_event) - 1)\n\n            if event_id not in event_id_list:\n                event_id_list.append(event_id)\n            else:\n                continue\n\n        return event_id_list\n\n    def get_info_about_loc(\n        self, df_loc: DataFrame, list_of_ids: List[int]\n    ) -&gt; List[List[Union[int, float]]]:\n        \"\"\"\n        Based on id of a location find some information about it and store in a list\n\n        Args:\n            df_loc (DataFrame): Set of locations of a network and their features to search in based on id\n            list_of_ids (List[int]): List of locations' ids to derive some information about\n\n        Returns:\n            List[List[Union[int, float]]]: List of lists, each element has three items: nearest node id and lat and lon coordinates of location's centroid\n        \"\"\"\n\n        list_of_info = []\n        for loc_id in list_of_ids:\n            list_of_info.append(\n                [\n                    df_loc.iloc[loc_id][\"nearest_node_id\"],\n                    df_loc.iloc[loc_id][\"geometry\"].x,\n                    df_loc.iloc[loc_id][\"geometry\"].y,\n                ]\n            )\n\n        return list_of_info\n\n    def create_list_of_locations(\n        self,\n        gdf_hw: GeoDataFrame,\n        gdf_event: GeoDataFrame,\n        home_id: int,\n        work_id: int,\n        regular_location_ids: List[int],\n        day_of_week: int,\n    ) -&gt; List[List[Union[int, float]]]:\n        \"\"\"\n        Based on day of week define type and number of locations to visit for a user within a day\n        and derive information about them\n\n        Args:\n            gdf_hw (GeoDataFrame): Set of locations (and their features) of a network to use from for home and work anchors\n            gdf_event (GeoDataFrame): Set of locations (and their features) of a network to use for regular and random event anchors\n            home_id (int): Id of home anchor\n            work_id (int): Id of work anchor\n            regular_location_ids (List[int]): List of regular event locations' ids\n            day_of_week (int): _description_\n\n        Returns:\n            List[List[Union[int, float]]]: List of lists, each element has three items: nearest node id and lat and lon coordinates of location's centroid\n\n        \"\"\"\n        if day_of_week &lt; 6:\n            number_of_events = random.choices(\n                [0, 1, 2, 3], weights=[0.6, 0.25, 0.1, 0.05], k=1\n            )[0]\n            list_of_ids = [home_id, work_id]\n        else:\n            number_of_events = random.choices(\n                [0, 1, 2, 3, 4], weights=[0.1, 0.2, 0.30, 0.25, 0.15], k=1\n            )[0]\n            list_of_ids = [home_id]\n\n        event_id_list = self.get_regular_or_random_loc(\n            gdf_event, regular_location_ids, number_of_events\n        )\n\n        list_of_locations_not_event = self.get_info_about_loc(gdf_hw, list_of_ids)\n        list_of_locations_event = self.get_info_about_loc(gdf_event, event_id_list)\n\n        list_of_locations = list_of_locations_not_event + list_of_locations_event\n\n        return list_of_locations\n\n    def get_static_points(\n        self,\n        user_id: int,\n        data_array: List[List[Union[int, float, Timestamp]]],\n        transformer_to_WGS: Transformer,\n        startlon: float,\n        startlat: float,\n        time_start: Timestamp,\n        time_end: Timestamp,\n    ) -&gt; Timestamp:\n        \"\"\"\n        Generate the nearby points around some coordinates (the centroid point of a user\u2019s location)\n\n        Args:\n            user_id (int): Id of a user\n            data_array (List[List[Union[int, float, Timestamp]]]): List to store user's GPS data (user_id, lon, lat, timestamp)\n            startlon (float): Longitude of a point where to start generating nearby points (more precisely their coordinates)\n            startlat (float): Latitude of a point where to start generating nearby points (more precisely their coordinates)\n            time_start (Timestamp): Timestamp from which to start generating static points\n            time_end (Timestamp): Upper timestamp limit of genaration\n\n        Returns:\n            Timestamp: Time from which to start generating GPS data for another activity\n        \"\"\"\n        time_start += timedelta(minutes=1)\n        startlon, startlat = transformer_to_WGS.transform(startlon, startlat)\n        while time_start &lt; time_end:\n            random_minutes = random.randint(1, 5)\n            possible_forward_azimuth = random.randint(0, 360)\n            possible_distance = random.randint(0, 5)  # metres\n            endLon, endLat, _ = Geod(ellps=\"WGS84\").fwd(\n                startlon, startlat, possible_forward_azimuth, possible_distance\n            )\n            time_gps = time_start\n            data_array.append([user_id, time_gps, endLon, endLat])\n            time_start += timedelta(minutes=random_minutes)\n\n        return time_start.round(freq=\"s\")\n\n    def get_points_on_path(\n        self, path: LineString, number_of_points: int\n    ) -&gt; List[Point]:\n        \"\"\"\n        Generate mostly equally distanced points along path between its start and end point\n\n        Args:\n            path (LineString): A line along which to generate points\n            number_of_points (int): Number of points to generate along the path (it includes the start and end point)\n\n        Returns:\n            List[Point]: List of points placed on the path\n        \"\"\"\n\n        distances = np.linspace(0, path.length, number_of_points)\n        points = [path.interpolate(distance) for distance in distances]\n\n        return points\n\n    def get_chaotic_point(\n        self,\n        point_start: Point,\n        point_end: Point,\n        radius_of_buffer: int,\n        proximity_to_road: int,\n    ) -&gt; Point:\n        \"\"\"\n        Produce one chaotic point between two points\n        meaning that with very high likelihood it will not be located on the path but near to it.\n        Applied to make a movement look more humanlike\n\n        Args:\n            point_start (Point): _description_\n            point_end (Point): _description_\n            radius_of_buffer (int): A radius to define a potential space for a chaotic point\n            proximity_to_road (int): A distance to define how a chaotic point should be from a path\n\n        Returns:\n            Point: A chaotic point\n        \"\"\"\n\n        points_intersection = point_start.buffer(radius_of_buffer).intersection(\n            point_end.buffer(radius_of_buffer)\n        )\n        path_between_points = LineString([point_start, point_end])\n        final_intersection = points_intersection.intersection(\n            path_between_points.buffer(proximity_to_road)\n        )\n        min_x, min_y, max_x, max_y = final_intersection.bounds\n        while True:\n            chaotic_point = Point(\n                [random.uniform(min_x, max_x), random.uniform(min_y, max_y)]\n            )\n            if chaotic_point.within(final_intersection):\n                return chaotic_point\n\n    def get_moving_points(\n        self,\n        user_id: int,\n        data_array: List[List[Union[int, float, Timestamp]]],\n        graph_proj: MultiDiGraph,\n        nodes: GeoDataFrame,\n        transformer_to_WGS: Transformer,\n        start_node: int,\n        end_node: int,\n        start_coords: Tuple[float, float],\n        end_coords: Tuple[float, float],\n        mean_move_speed_ms: Union[int, float],\n        proximity_to_road: int,\n        time_start: Timestamp,\n    ) -&gt; Timestamp:\n        \"\"\"\n        First create route between origin and destination locations, interpolate this path with points,\n        and create GPS data while moving from point to point\n\n        Args:\n            user_id (int): Id of a user\n            data_array (List[List[Union[int, float, Timestamp]]]): List to store user's GPS data (user_id, lon, lat, timestamp)\n            graph_proj (MultiDiGraph): Projected graph of a network\n            nodes (GeoDataFrame): Nodes of netwrok's projected graph\n            start_node (int): Id of the nearest node to a start location\n            end_node (int): Id of the nearest node to an end location\n            start_coords Tuple[float, float]: Lon and lat of start location\n            end_coords Tuple[float, float]: Lon and lat of end location\n            mean_move_speed_ms Union[int, float]: _description_\n            proximity_to_road (int): A distance to define how a chaotic point should be from a path\n            time_start (Timestamp): Timestamp from which to start generating moving points\n\n        Returns:\n            Timestamp: Time from which to start generating GPS data for another activity\n        \"\"\"\n        # get the shortest route from start to end node\n        route = ox.distance.shortest_path(\n            graph_proj, start_node, end_node, weight=\"length\"\n        )\n        route_nodes = nodes.loc[route]\n        route_list = list(route_nodes.geometry.values)\n        # add start location's coordinates to the beggining\n        # add end location's coordinates to the end\n        # not all always locations are near to a network\n        route_list.insert(0, Point(start_coords[0], start_coords[1]))\n        route_list.append(Point(end_coords[0], end_coords[1]))\n        path = LineString(route_list)\n\n        # to make sure that the time difference between\n        # two consecutive points is not higher than 10 seconds\n        # To mimic GPS tracking frequency (it could be even 1 second, but then the amount of data could be enormous)\n        min_dist_between_conseq_points = mean_move_speed_ms * 10\n\n        if path.length &lt;= min_dist_between_conseq_points:\n            number_of_points = 2\n        else:\n            number_of_points = math.ceil(path.length / min_dist_between_conseq_points)\n\n        points = self.get_points_on_path(path, number_of_points)\n\n        # iterate through each point of created route\n        for i in range(number_of_points):\n            # even though the actual path and points are in projected CRS\n            # the final coordinates should be in WGS 84\n            endLon, endLat = transformer_to_WGS.transform(points[i].x, points[i].y)\n            # if not a last point calculate a chaotic point\n            if i != number_of_points - 1:\n                chaotic_point = self.get_chaotic_point(\n                    points[i],\n                    points[i + 1],\n                    min_dist_between_conseq_points,\n                    proximity_to_road,\n                )\n                distance_to_chaotic_point = LineString(\n                    [points[i], chaotic_point]\n                ).length\n                # discard situations when start point and a chaotic point are too close and thus time difference would be too small\n                # we build the model and don't want to use a lot of memory\n                if distance_to_chaotic_point &lt; mean_move_speed_ms * 2:\n                    time_to_chaotic_point = 2\n                else:\n                    time_to_chaotic_point = (\n                        distance_to_chaotic_point / mean_move_speed_ms\n                    )\n\n                # Add current point's coordinates and the time it was registered in data array\n                time_gps = time_start.round(freq=\"s\")\n                data_array.append([user_id, time_gps, endLon, endLat])\n\n                # Add time taken to reach a chaotic point\n                time_start += timedelta(seconds=time_to_chaotic_point)\n\n                # Change the current coordinates to coordinate of a chaotic point and project to WGS 84\n                endLon, endLat = transformer_to_WGS.transform(\n                    chaotic_point.x, chaotic_point.y\n                )\n                # Lenght from chaotic point to the next point or maybe it will be more clear - end point\n                distance_to_next_point = LineString(\n                    [chaotic_point, points[i + 1]]\n                ).length\n                # discard to precise situations\n                if distance_to_next_point &lt; mean_move_speed_ms * 2:\n                    time_to_next_point = 2\n                else:\n                    time_to_next_point = distance_to_next_point / mean_move_speed_ms\n\n                # Add chaotic point's coordinates and the time it was registered in data array\n                time_gps = time_start.round(freq=\"s\")\n                data_array.append([user_id, time_gps, endLon, endLat])\n\n                # Add time taken to reach a the next point\n                # It will become a start time of the next iteration of a loop\n                time_start += timedelta(seconds=time_to_next_point)\n\n            # if last point in the route - add it and its time to data array\n            else:\n                endLon, endLat = transformer_to_WGS.transform(points[i].x, points[i].y)\n                time_gps = time_start.round(freq=\"s\")\n                data_array.append([user_id, time_gps, endLon, endLat])\n\n        return time_start.round(freq=\"s\")\n\n    @abstractmethod\n    def random_plot_of_day(\n        self,\n        time_start: Timestamp,\n        beggining_of_day: Timestamp,\n        day_of_week: int,\n        list_of_locations: List[List[Union[int, float]]],\n        network_graph_proj: MultiDiGraph,\n        network_nodes: GeoDataFrame,\n        transformer_to_WGS: Transformer,\n    ) -&gt; Timestamp:\n        # pylint: disable=missing-function-docstring\n        pass\n\n    @abstractmethod\n    def generate_gps(\n        self,\n        network_gdf_hw: GeoDataFrame,\n        network_gdf_event: GeoDataFrame,\n        network_graph_proj: MultiDiGraph,\n        network_nodes: GeoDataFrame,\n        transformer_to_WGS: Transformer,\n    ):\n        # pylint: disable=missing-function-docstring\n        pass\n</code></pre>"},{"location":"reference/common/abs_user/#common.abs_user.User.create_list_of_locations","title":"<code>create_list_of_locations(gdf_hw, gdf_event, home_id, work_id, regular_location_ids, day_of_week)</code>","text":"<p>Based on day of week define type and number of locations to visit for a user within a day and derive information about them</p> <p>Parameters:</p> Name Type Description Default <code>gdf_hw</code> <code>GeoDataFrame</code> <p>Set of locations (and their features) of a network to use from for home and work anchors</p> required <code>gdf_event</code> <code>GeoDataFrame</code> <p>Set of locations (and their features) of a network to use for regular and random event anchors</p> required <code>home_id</code> <code>int</code> <p>Id of home anchor</p> required <code>work_id</code> <code>int</code> <p>Id of work anchor</p> required <code>regular_location_ids</code> <code>List[int]</code> <p>List of regular event locations' ids</p> required <code>day_of_week</code> <code>int</code> <p>description</p> required <p>Returns:</p> Type Description <code>List[List[Union[int, float]]]</code> <p>List[List[Union[int, float]]]: List of lists, each element has three items: nearest node id and lat and lon coordinates of location's centroid</p> Source code in <code>gps_synth/common/abs_user.py</code> <pre><code>def create_list_of_locations(\n    self,\n    gdf_hw: GeoDataFrame,\n    gdf_event: GeoDataFrame,\n    home_id: int,\n    work_id: int,\n    regular_location_ids: List[int],\n    day_of_week: int,\n) -&gt; List[List[Union[int, float]]]:\n    \"\"\"\n    Based on day of week define type and number of locations to visit for a user within a day\n    and derive information about them\n\n    Args:\n        gdf_hw (GeoDataFrame): Set of locations (and their features) of a network to use from for home and work anchors\n        gdf_event (GeoDataFrame): Set of locations (and their features) of a network to use for regular and random event anchors\n        home_id (int): Id of home anchor\n        work_id (int): Id of work anchor\n        regular_location_ids (List[int]): List of regular event locations' ids\n        day_of_week (int): _description_\n\n    Returns:\n        List[List[Union[int, float]]]: List of lists, each element has three items: nearest node id and lat and lon coordinates of location's centroid\n\n    \"\"\"\n    if day_of_week &lt; 6:\n        number_of_events = random.choices(\n            [0, 1, 2, 3], weights=[0.6, 0.25, 0.1, 0.05], k=1\n        )[0]\n        list_of_ids = [home_id, work_id]\n    else:\n        number_of_events = random.choices(\n            [0, 1, 2, 3, 4], weights=[0.1, 0.2, 0.30, 0.25, 0.15], k=1\n        )[0]\n        list_of_ids = [home_id]\n\n    event_id_list = self.get_regular_or_random_loc(\n        gdf_event, regular_location_ids, number_of_events\n    )\n\n    list_of_locations_not_event = self.get_info_about_loc(gdf_hw, list_of_ids)\n    list_of_locations_event = self.get_info_about_loc(gdf_event, event_id_list)\n\n    list_of_locations = list_of_locations_not_event + list_of_locations_event\n\n    return list_of_locations\n</code></pre>"},{"location":"reference/common/abs_user/#common.abs_user.User.get_chaotic_point","title":"<code>get_chaotic_point(point_start, point_end, radius_of_buffer, proximity_to_road)</code>","text":"<p>Produce one chaotic point between two points meaning that with very high likelihood it will not be located on the path but near to it. Applied to make a movement look more humanlike</p> <p>Parameters:</p> Name Type Description Default <code>point_start</code> <code>Point</code> <p>description</p> required <code>point_end</code> <code>Point</code> <p>description</p> required <code>radius_of_buffer</code> <code>int</code> <p>A radius to define a potential space for a chaotic point</p> required <code>proximity_to_road</code> <code>int</code> <p>A distance to define how a chaotic point should be from a path</p> required <p>Returns:</p> Name Type Description <code>Point</code> <code>Point</code> <p>A chaotic point</p> Source code in <code>gps_synth/common/abs_user.py</code> <pre><code>def get_chaotic_point(\n    self,\n    point_start: Point,\n    point_end: Point,\n    radius_of_buffer: int,\n    proximity_to_road: int,\n) -&gt; Point:\n    \"\"\"\n    Produce one chaotic point between two points\n    meaning that with very high likelihood it will not be located on the path but near to it.\n    Applied to make a movement look more humanlike\n\n    Args:\n        point_start (Point): _description_\n        point_end (Point): _description_\n        radius_of_buffer (int): A radius to define a potential space for a chaotic point\n        proximity_to_road (int): A distance to define how a chaotic point should be from a path\n\n    Returns:\n        Point: A chaotic point\n    \"\"\"\n\n    points_intersection = point_start.buffer(radius_of_buffer).intersection(\n        point_end.buffer(radius_of_buffer)\n    )\n    path_between_points = LineString([point_start, point_end])\n    final_intersection = points_intersection.intersection(\n        path_between_points.buffer(proximity_to_road)\n    )\n    min_x, min_y, max_x, max_y = final_intersection.bounds\n    while True:\n        chaotic_point = Point(\n            [random.uniform(min_x, max_x), random.uniform(min_y, max_y)]\n        )\n        if chaotic_point.within(final_intersection):\n            return chaotic_point\n</code></pre>"},{"location":"reference/common/abs_user/#common.abs_user.User.get_info_about_loc","title":"<code>get_info_about_loc(df_loc, list_of_ids)</code>","text":"<p>Based on id of a location find some information about it and store in a list</p> <p>Parameters:</p> Name Type Description Default <code>df_loc</code> <code>DataFrame</code> <p>Set of locations of a network and their features to search in based on id</p> required <code>list_of_ids</code> <code>List[int]</code> <p>List of locations' ids to derive some information about</p> required <p>Returns:</p> Type Description <code>List[List[Union[int, float]]]</code> <p>List[List[Union[int, float]]]: List of lists, each element has three items: nearest node id and lat and lon coordinates of location's centroid</p> Source code in <code>gps_synth/common/abs_user.py</code> <pre><code>def get_info_about_loc(\n    self, df_loc: DataFrame, list_of_ids: List[int]\n) -&gt; List[List[Union[int, float]]]:\n    \"\"\"\n    Based on id of a location find some information about it and store in a list\n\n    Args:\n        df_loc (DataFrame): Set of locations of a network and their features to search in based on id\n        list_of_ids (List[int]): List of locations' ids to derive some information about\n\n    Returns:\n        List[List[Union[int, float]]]: List of lists, each element has three items: nearest node id and lat and lon coordinates of location's centroid\n    \"\"\"\n\n    list_of_info = []\n    for loc_id in list_of_ids:\n        list_of_info.append(\n            [\n                df_loc.iloc[loc_id][\"nearest_node_id\"],\n                df_loc.iloc[loc_id][\"geometry\"].x,\n                df_loc.iloc[loc_id][\"geometry\"].y,\n            ]\n        )\n\n    return list_of_info\n</code></pre>"},{"location":"reference/common/abs_user/#common.abs_user.User.get_meaningful_locations","title":"<code>get_meaningful_locations(gdf_hw, gdf_event)</code>","text":"<p>Create meaningful locations for a user: one home, one work, several regular events, the radius between home and work and home and regular locations are defined in the config The distribution of meaningful locations should follow some distance conditions. Store computed anchors in correponding instance attributes</p> <p>Parameters:</p> Name Type Description Default <code>gdf_hw</code> <code>GeoDataFrame</code> <p>Set of locations of a network to choose from for home and work anchors</p> required <code>gdf_event</code> <code>GeoDataFrame</code> <p>Set of locations of a network to choose from for regular event anchors</p> required Source code in <code>gps_synth/common/abs_user.py</code> <pre><code>def get_meaningful_locations(\n    self,\n    gdf_hw: GeoDataFrame,\n    gdf_event: GeoDataFrame,\n) -&gt; None:\n    \"\"\"\n    Create meaningful locations for a user: one home, one work, several regular events,\n    the radius between home and work and home and regular locations are defined in the config\n    The distribution of meaningful locations should follow some distance conditions.\n    Store computed anchors in correponding instance attributes\n\n    Args:\n        gdf_hw (GeoDataFrame): Set of locations of a network to choose from for home and work anchors\n        gdf_event (GeoDataFrame): Set of locations of a network to choose from for regular event anchors\n    \"\"\"\n    # radius_buffer_h_w (int): Radius to create a buffer around home anchor to search for work anchor\n    radius_buffer_h_w = self.radius_buffer_h_w\n    # radius_buffer_h_w (int): Radius to create a buffer around home anchor to search for regular event anchors\n    radius_buffer_h_r = self.radius_buffer_h_r\n\n    home_id = random.randint(0, len(gdf_hw) - 1)\n    home_geometry = gdf_hw.iloc[home_id][\"geometry\"]\n    # TODO: too conditionally nested think about a better approach\n    while True:\n\n        work_id = self.get_random_id_within_buffer(\n            home_geometry, radius_buffer_h_w, gdf_hw\n        )\n        # if there are not many possible work anchor locations around\n        if work_id is None:\n            # change home id\n            home_id = random.randint(0, len(gdf_hw) - 1)\n            home_geometry = gdf_hw.iloc[home_id][\"geometry\"]\n        # if the same just choose another work id, but don't change home anchor\n        elif home_id == work_id:\n            continue\n\n        else:\n            regular_locations_ids = []\n            number_of_regular_locations = random.randint(3, 5)\n            i = 0\n            while i &lt;= number_of_regular_locations:\n                regular_id = self.get_random_id_within_buffer(\n                    home_geometry, radius_buffer_h_r, gdf_event\n                )\n\n                # if there are not many possible regular event anchors around increase search radius\n                if regular_id is None:\n                    radius_buffer_h_r += 100\n                # if id is already used, chooses another one\n                elif (\n                    regular_id in regular_locations_ids\n                    or regular_id == home_id\n                    or regular_id == work_id\n                ):\n                    continue\n                else:\n                    regular_locations_ids.append(regular_id)\n                    i += 1\n\n            self.home_id = home_id\n            self.work_id = work_id\n            self.regular_loc_array = regular_locations_ids\n            break\n</code></pre>"},{"location":"reference/common/abs_user/#common.abs_user.User.get_moving_points","title":"<code>get_moving_points(user_id, data_array, graph_proj, nodes, transformer_to_WGS, start_node, end_node, start_coords, end_coords, mean_move_speed_ms, proximity_to_road, time_start)</code>","text":"<p>First create route between origin and destination locations, interpolate this path with points, and create GPS data while moving from point to point</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>int</code> <p>Id of a user</p> required <code>data_array</code> <code>List[List[Union[int, float, Timestamp]]]</code> <p>List to store user's GPS data (user_id, lon, lat, timestamp)</p> required <code>graph_proj</code> <code>MultiDiGraph</code> <p>Projected graph of a network</p> required <code>nodes</code> <code>GeoDataFrame</code> <p>Nodes of netwrok's projected graph</p> required <code>start_node</code> <code>int</code> <p>Id of the nearest node to a start location</p> required <code>end_node</code> <code>int</code> <p>Id of the nearest node to an end location</p> required <code>start_coords</code> <code>Tuple[float, float]</code> <p>Lon and lat of start location</p> required <code>end_coords</code> <code>Tuple[float, float]</code> <p>Lon and lat of end location</p> required <code>mean_move_speed_ms</code> <code>Union[int, float]</code> <p>description</p> required <code>proximity_to_road</code> <code>int</code> <p>A distance to define how a chaotic point should be from a path</p> required <code>time_start</code> <code>Timestamp</code> <p>Timestamp from which to start generating moving points</p> required <p>Returns:</p> Name Type Description <code>Timestamp</code> <code>Timestamp</code> <p>Time from which to start generating GPS data for another activity</p> Source code in <code>gps_synth/common/abs_user.py</code> <pre><code>def get_moving_points(\n    self,\n    user_id: int,\n    data_array: List[List[Union[int, float, Timestamp]]],\n    graph_proj: MultiDiGraph,\n    nodes: GeoDataFrame,\n    transformer_to_WGS: Transformer,\n    start_node: int,\n    end_node: int,\n    start_coords: Tuple[float, float],\n    end_coords: Tuple[float, float],\n    mean_move_speed_ms: Union[int, float],\n    proximity_to_road: int,\n    time_start: Timestamp,\n) -&gt; Timestamp:\n    \"\"\"\n    First create route between origin and destination locations, interpolate this path with points,\n    and create GPS data while moving from point to point\n\n    Args:\n        user_id (int): Id of a user\n        data_array (List[List[Union[int, float, Timestamp]]]): List to store user's GPS data (user_id, lon, lat, timestamp)\n        graph_proj (MultiDiGraph): Projected graph of a network\n        nodes (GeoDataFrame): Nodes of netwrok's projected graph\n        start_node (int): Id of the nearest node to a start location\n        end_node (int): Id of the nearest node to an end location\n        start_coords Tuple[float, float]: Lon and lat of start location\n        end_coords Tuple[float, float]: Lon and lat of end location\n        mean_move_speed_ms Union[int, float]: _description_\n        proximity_to_road (int): A distance to define how a chaotic point should be from a path\n        time_start (Timestamp): Timestamp from which to start generating moving points\n\n    Returns:\n        Timestamp: Time from which to start generating GPS data for another activity\n    \"\"\"\n    # get the shortest route from start to end node\n    route = ox.distance.shortest_path(\n        graph_proj, start_node, end_node, weight=\"length\"\n    )\n    route_nodes = nodes.loc[route]\n    route_list = list(route_nodes.geometry.values)\n    # add start location's coordinates to the beggining\n    # add end location's coordinates to the end\n    # not all always locations are near to a network\n    route_list.insert(0, Point(start_coords[0], start_coords[1]))\n    route_list.append(Point(end_coords[0], end_coords[1]))\n    path = LineString(route_list)\n\n    # to make sure that the time difference between\n    # two consecutive points is not higher than 10 seconds\n    # To mimic GPS tracking frequency (it could be even 1 second, but then the amount of data could be enormous)\n    min_dist_between_conseq_points = mean_move_speed_ms * 10\n\n    if path.length &lt;= min_dist_between_conseq_points:\n        number_of_points = 2\n    else:\n        number_of_points = math.ceil(path.length / min_dist_between_conseq_points)\n\n    points = self.get_points_on_path(path, number_of_points)\n\n    # iterate through each point of created route\n    for i in range(number_of_points):\n        # even though the actual path and points are in projected CRS\n        # the final coordinates should be in WGS 84\n        endLon, endLat = transformer_to_WGS.transform(points[i].x, points[i].y)\n        # if not a last point calculate a chaotic point\n        if i != number_of_points - 1:\n            chaotic_point = self.get_chaotic_point(\n                points[i],\n                points[i + 1],\n                min_dist_between_conseq_points,\n                proximity_to_road,\n            )\n            distance_to_chaotic_point = LineString(\n                [points[i], chaotic_point]\n            ).length\n            # discard situations when start point and a chaotic point are too close and thus time difference would be too small\n            # we build the model and don't want to use a lot of memory\n            if distance_to_chaotic_point &lt; mean_move_speed_ms * 2:\n                time_to_chaotic_point = 2\n            else:\n                time_to_chaotic_point = (\n                    distance_to_chaotic_point / mean_move_speed_ms\n                )\n\n            # Add current point's coordinates and the time it was registered in data array\n            time_gps = time_start.round(freq=\"s\")\n            data_array.append([user_id, time_gps, endLon, endLat])\n\n            # Add time taken to reach a chaotic point\n            time_start += timedelta(seconds=time_to_chaotic_point)\n\n            # Change the current coordinates to coordinate of a chaotic point and project to WGS 84\n            endLon, endLat = transformer_to_WGS.transform(\n                chaotic_point.x, chaotic_point.y\n            )\n            # Lenght from chaotic point to the next point or maybe it will be more clear - end point\n            distance_to_next_point = LineString(\n                [chaotic_point, points[i + 1]]\n            ).length\n            # discard to precise situations\n            if distance_to_next_point &lt; mean_move_speed_ms * 2:\n                time_to_next_point = 2\n            else:\n                time_to_next_point = distance_to_next_point / mean_move_speed_ms\n\n            # Add chaotic point's coordinates and the time it was registered in data array\n            time_gps = time_start.round(freq=\"s\")\n            data_array.append([user_id, time_gps, endLon, endLat])\n\n            # Add time taken to reach a the next point\n            # It will become a start time of the next iteration of a loop\n            time_start += timedelta(seconds=time_to_next_point)\n\n        # if last point in the route - add it and its time to data array\n        else:\n            endLon, endLat = transformer_to_WGS.transform(points[i].x, points[i].y)\n            time_gps = time_start.round(freq=\"s\")\n            data_array.append([user_id, time_gps, endLon, endLat])\n\n    return time_start.round(freq=\"s\")\n</code></pre>"},{"location":"reference/common/abs_user/#common.abs_user.User.get_points_on_path","title":"<code>get_points_on_path(path, number_of_points)</code>","text":"<p>Generate mostly equally distanced points along path between its start and end point</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>LineString</code> <p>A line along which to generate points</p> required <code>number_of_points</code> <code>int</code> <p>Number of points to generate along the path (it includes the start and end point)</p> required <p>Returns:</p> Type Description <code>List[Point]</code> <p>List[Point]: List of points placed on the path</p> Source code in <code>gps_synth/common/abs_user.py</code> <pre><code>def get_points_on_path(\n    self, path: LineString, number_of_points: int\n) -&gt; List[Point]:\n    \"\"\"\n    Generate mostly equally distanced points along path between its start and end point\n\n    Args:\n        path (LineString): A line along which to generate points\n        number_of_points (int): Number of points to generate along the path (it includes the start and end point)\n\n    Returns:\n        List[Point]: List of points placed on the path\n    \"\"\"\n\n    distances = np.linspace(0, path.length, number_of_points)\n    points = [path.interpolate(distance) for distance in distances]\n\n    return points\n</code></pre>"},{"location":"reference/common/abs_user/#common.abs_user.User.get_random_id_within_buffer","title":"<code>get_random_id_within_buffer(center_point, radius_buffer, gdf_locations)</code>","text":"<p>Find a random id of a location which is within a buffer, created around center point with specified distance. A center point should be surronded with some amount of needed locations, otherwise None</p> <p>Parameters:</p> Name Type Description Default <code>center_point</code> <code>Point</code> <p>A point around which create a buffer</p> required <code>radius_buffer</code> <code>int</code> <p>A radius of a buffer</p> required <code>gdf_locations</code> <code>GeoDataFrame</code> <p>Locations to filter with condition \"within a buffer\"</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>Union[int, None]</code> <p>Random id among filtered loctions or None if home anchor is too near to border of a place</p> Source code in <code>gps_synth/common/abs_user.py</code> <pre><code>def get_random_id_within_buffer(\n    self, center_point: Point, radius_buffer: int, gdf_locations: GeoDataFrame\n) -&gt; Union[int, None]:\n    \"\"\"\n    Find a random id of a location which is within a buffer, created around center point with specified distance.\n    A center point should be surronded with some amount of needed locations, otherwise None\n\n    Args:\n        center_point (Point): A point around which create a buffer\n        radius_buffer (int): A radius of a buffer\n        gdf_locations (GeoDataFrame): Locations to filter with condition \"within a buffer\"\n\n    Returns:\n        int: Random id among filtered loctions or None if home anchor is too near to border of a place\n    \"\"\"\n\n    buffer = shapely.buffer(center_point, distance=radius_buffer)\n    index_list = gdf_locations[gdf_locations.within(buffer)].index\n    # TODO: 20 is arbitary threshold, e.g. there could be just a case that a place does not have\n    # some types of locations in many quantaties, think about how logically define this value\n    # and make it as another positional argument\n    if len(index_list) &gt;= 20:\n        random_id = random.choice(gdf_locations[gdf_locations.within(buffer)].index)\n        return random_id\n\n    return None\n</code></pre>"},{"location":"reference/common/abs_user/#common.abs_user.User.get_regular_or_random_loc","title":"<code>get_regular_or_random_loc(gdf_event, regular_location_ids, number_of_events)</code>","text":"<p>Randomly create a list with specified number of event ids, which could be either from regular event locations or completely accidental</p> <p>Parameters:</p> Name Type Description Default <code>gdf_event</code> <code>GeoDataFrame</code> <p>Set of locations of a network to choose from for regular event anchors</p> required <code>regular_location_ids</code> <code>List[int]</code> <p>List of regular event locations' ids</p> required <code>number_of_events</code> <code>int</code> <p>A number of event ids tom create</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>List[int]: List of event ids for a userto visit within a day</p> Source code in <code>gps_synth/common/abs_user.py</code> <pre><code>def get_regular_or_random_loc(\n    self,\n    gdf_event: GeoDataFrame,\n    regular_location_ids: List[int],\n    number_of_events: int,\n) -&gt; List[int]:\n    \"\"\"\n    Randomly create a list with specified number of event ids, which could be either from regular event locations or completely accidental\n\n    Args:\n        gdf_event (GeoDataFrame): Set of locations of a network to choose from for regular event anchors\n        regular_location_ids (List[int]): List of regular event locations' ids\n        number_of_events (int): A number of event ids tom create\n\n    Returns:\n        List[int]: List of event ids for a userto visit within a day\n    \"\"\"\n    event_id_list = []\n    while len(event_id_list) &lt; number_of_events:\n        choose_reg_or_random = random.choices(\n            [\"reg\", \"random\"], weights=[0.6, 0.4], k=1\n        )[0]\n        if choose_reg_or_random == \"reg\":\n            event_id = random.choice(regular_location_ids)\n        else:\n            event_id = random.randint(0, len(gdf_event) - 1)\n\n        if event_id not in event_id_list:\n            event_id_list.append(event_id)\n        else:\n            continue\n\n    return event_id_list\n</code></pre>"},{"location":"reference/common/abs_user/#common.abs_user.User.get_static_points","title":"<code>get_static_points(user_id, data_array, transformer_to_WGS, startlon, startlat, time_start, time_end)</code>","text":"<p>Generate the nearby points around some coordinates (the centroid point of a user\u2019s location)</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>int</code> <p>Id of a user</p> required <code>data_array</code> <code>List[List[Union[int, float, Timestamp]]]</code> <p>List to store user's GPS data (user_id, lon, lat, timestamp)</p> required <code>startlon</code> <code>float</code> <p>Longitude of a point where to start generating nearby points (more precisely their coordinates)</p> required <code>startlat</code> <code>float</code> <p>Latitude of a point where to start generating nearby points (more precisely their coordinates)</p> required <code>time_start</code> <code>Timestamp</code> <p>Timestamp from which to start generating static points</p> required <code>time_end</code> <code>Timestamp</code> <p>Upper timestamp limit of genaration</p> required <p>Returns:</p> Name Type Description <code>Timestamp</code> <code>Timestamp</code> <p>Time from which to start generating GPS data for another activity</p> Source code in <code>gps_synth/common/abs_user.py</code> <pre><code>def get_static_points(\n    self,\n    user_id: int,\n    data_array: List[List[Union[int, float, Timestamp]]],\n    transformer_to_WGS: Transformer,\n    startlon: float,\n    startlat: float,\n    time_start: Timestamp,\n    time_end: Timestamp,\n) -&gt; Timestamp:\n    \"\"\"\n    Generate the nearby points around some coordinates (the centroid point of a user\u2019s location)\n\n    Args:\n        user_id (int): Id of a user\n        data_array (List[List[Union[int, float, Timestamp]]]): List to store user's GPS data (user_id, lon, lat, timestamp)\n        startlon (float): Longitude of a point where to start generating nearby points (more precisely their coordinates)\n        startlat (float): Latitude of a point where to start generating nearby points (more precisely their coordinates)\n        time_start (Timestamp): Timestamp from which to start generating static points\n        time_end (Timestamp): Upper timestamp limit of genaration\n\n    Returns:\n        Timestamp: Time from which to start generating GPS data for another activity\n    \"\"\"\n    time_start += timedelta(minutes=1)\n    startlon, startlat = transformer_to_WGS.transform(startlon, startlat)\n    while time_start &lt; time_end:\n        random_minutes = random.randint(1, 5)\n        possible_forward_azimuth = random.randint(0, 360)\n        possible_distance = random.randint(0, 5)  # metres\n        endLon, endLat, _ = Geod(ellps=\"WGS84\").fwd(\n            startlon, startlat, possible_forward_azimuth, possible_distance\n        )\n        time_gps = time_start\n        data_array.append([user_id, time_gps, endLon, endLat])\n        time_start += timedelta(minutes=random_minutes)\n\n    return time_start.round(freq=\"s\")\n</code></pre>"},{"location":"reference/common/columns/","title":"columns","text":"<p>Reusable internal column names. Useful for referring to the the same column across multiple modules.</p>"},{"location":"reference/common/columns/#common.columns.ColNames","title":"<code>ColNames</code>","text":"<p>Class that enumerates all the column names.</p> Source code in <code>gps_synth/common/columns.py</code> <pre><code>class ColNames:\n    \"\"\"\n    Class that enumerates all the column names.\n    \"\"\"\n\n    user_id = \"user_id\"\n    timestamp = \"timestamp\"\n    lon = \"lon\"\n    lat = \"lat\"\n    profile_name = \"profile_name\"\n    network_name = \"network_name\"\n    centre_x = \"centre_x\"\n    centre_y = \"centre_y\"\n    home_id = \"home_id\"\n    work_id = \"work_id\"\n    regular_loc_array = \"regular_loc_array\"\n</code></pre>"},{"location":"reference/common/functions/","title":"functions","text":""},{"location":"reference/common/functions/#common.functions.check_or_create_dir","title":"<code>check_or_create_dir(directory)</code>","text":"<p>Check if a directory exists and create it if it doesn't</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>The directory path</p> required Source code in <code>gps_synth/common/functions.py</code> <pre><code>def check_or_create_dir(directory: str) -&gt; None:\n    \"\"\"\n    Check if a directory exists and create it if it doesn't\n\n    Args:\n        directory (str): The directory path\n    \"\"\"\n\n    try:\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n    except OSError as e:\n        print(f\"Unable to handle input directory path '{directory}': {e}\")\n        raise\n</code></pre>"},{"location":"reference/common/functions/#common.functions.class_getter","title":"<code>class_getter(module_path, class_name)</code>","text":"<p>Create a pecified class</p> <p>Parameters:</p> Name Type Description Default <code>module_path</code> <code>str</code> <p>description</p> required <code>class_name</code> <code>str</code> <p>description</p> required <p>Returns:</p> Name Type Description <code>Type</code> <code>Type</code> <p>A class (https://stackoverflow.com/a/23198094)</p> Source code in <code>gps_synth/common/functions.py</code> <pre><code>def class_getter(module_path: str, class_name: str) -&gt; Type:\n    \"\"\"\n    Create a pecified class\n\n    Args:\n        module_path (str): _description_\n        class_name (str): _description_\n\n    Returns:\n        Type: A class (https://stackoverflow.com/a/23198094)\n    \"\"\"\n    module = importlib.import_module(module_path)\n    class_result = getattr(module, class_name)\n\n    return class_result\n</code></pre>"},{"location":"reference/common/functions/#common.functions.delete_directory","title":"<code>delete_directory(directory)</code>","text":"<p>Delete a directory both Empty or Non-Empty</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>The directory path</p> required Source code in <code>gps_synth/common/functions.py</code> <pre><code>def delete_directory(directory: str) -&gt; None:\n    \"\"\"\n    Delete a directory both Empty or Non-Empty\n\n    Args:\n        directory (str): The directory path\n    \"\"\"\n\n    try:\n        shutil.rmtree(directory)\n    except OSError as e:\n        print(f\"Unable to handle input directory path '{directory}': {e}\")\n        raise\n</code></pre>"},{"location":"reference/common/functions/#common.functions.write_df_to_parquet","title":"<code>write_df_to_parquet(df, base_dir, partition_cols=None, existing_data_behavior=None)</code>","text":"<p>Writes dataframe to Parquet If df is empty, writes a file When using the same path, but with data, the file gets overwritten</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Dataframe to write in parquet</p> required <code>base_dir</code> <code>str</code> <p>Base directory where to write data</p> required <code>partition_cols</code> <code>Optional[List[str]] = None</code> <p>A list of columns to use for partitioning, if None use [profile_name]</p> <code>None</code> <code>existing_data_behavior</code> <code>str</code> <p>Controls how the dataset will handle data that already exists in the destination</p> <code>None</code> Source code in <code>gps_synth/common/functions.py</code> <pre><code>def write_df_to_parquet(\n    df: DataFrame,\n    base_dir: str,\n    partition_cols: Optional[List[str]] = None,\n    existing_data_behavior: Optional[str] = None,\n) -&gt; None:\n    \"\"\"\n    Writes dataframe to Parquet\n    If df is empty, writes a file\n    When using the same path, but with data, the file gets overwritten\n\n    Args:\n        df (DataFrame): Dataframe to write in parquet\n        base_dir (str): Base directory where to write data\n        partition_cols (Optional[List[str]] = None): A list of columns to use for partitioning, if None use [profile_name]\n        existing_data_behavior (str): Controls how the dataset will handle data that already exists in the destination\n    \"\"\"\n\n    partition_cols = [\"profile_name\"] if partition_cols is None else partition_cols\n\n    existing_data_behavior = (\n        \"overwrite_or_ignore\"\n        if existing_data_behavior is None\n        else existing_data_behavior\n    )\n\n    # If empty df was saved earlier, we need to delete it\n    # in order to save the partitioned stuff\n    if os.path.exists(base_dir) and os.path.isfile(base_dir):\n        os.remove(base_dir)\n\n    table = pa.Table.from_pandas(df)\n\n    del df\n\n    # if path exists - overwrite\n    # if path is unqiue - append\n    ds.write_dataset(\n        table,\n        base_dir=base_dir,\n        format=\"parquet\",\n        partitioning=partition_cols,\n        existing_data_behavior=existing_data_behavior,\n        partitioning_flavor=\"hive\",\n        basename_template=\"part-{i}\" + f\"{uuid.uuid4().hex}.parquet\",\n    )\n</code></pre>"},{"location":"reference/gps_generator/","title":"gps_generator","text":""},{"location":"reference/gps_generator/gps_generator/","title":"gps_generator","text":""},{"location":"reference/gps_generator/gps_generator/#gps_generator.gps_generator.GPS_Generator","title":"<code>GPS_Generator</code>","text":"Source code in <code>gps_synth/gps_generator/gps_generator.py</code> <pre><code>class GPS_Generator:\n    def __init__(self, config, base_dir):\n        self.config = config\n        self.logger = logging.getLogger(__name__)\n\n        self.network_dictionary = {}\n        self.users_dictionary = {}\n        # to connect users/profiles with their corresponding network\n        self.users_network_dict = {}\n\n        for output in self.config[\"OUTPUTS\"]:\n            output_path = os.path.join(base_dir, self.config[\"OUTPUTS\"][output][\"PATH\"])\n            if self.config[\"DO_CLEAR_OUTPUT\"] is True:\n                delete_directory(output_path)\n            check_or_create_dir(output_path)\n            self.config[\"OUTPUTS\"][output][\"PATH\"] = output_path\n\n    def create_network(self, profile_network_config: Any) -&gt; Network:\n        \"\"\"\n        Initialise Network class and run it\n\n        Args:\n            profile_network_config (Any): YAML object with config params regarding network\n\n        Returns:\n            Network: Instance of Network class with completed run method\n        \"\"\"\n\n        network_class = class_getter(\n            profile_network_config[\"NETWORK_MODULE_PATH\"],\n            profile_network_config[\"NETWORK_CLASS\"],\n        )\n\n        network = network_class(profile_network_config)\n\n        network.run()\n\n        return network\n\n    def generate_users(self, profile_user_config: Any) -&gt; List[User]:\n        \"\"\"\n        Initialise User class and run it as many times as specified in NUM_USERS config param.\n        Store instances in a list\n\n        Args:\n            profile_user_config (Any): YAML object with config params regarding users\n\n        Returns:\n            List[User]: list of instances of User class with completed run method\n        \"\"\"\n        users_array = []\n\n        user_class = class_getter(\n            profile_user_config[\"USER_MODULE_PATH\"], profile_user_config[\"USER_CLASS\"]\n        )\n\n        for _ in range(profile_user_config[\"NUM_USERS\"]):\n            # ensure uniqueness of user ids in case of appending parquets\n            user_id = uuid.uuid4().hex\n            new_user = user_class(user_id, profile_user_config)\n            users_array.append(new_user)\n\n        return users_array\n\n    def execute_method_for_users(\n        self, users: List[User], method_name: str, args: List = None\n    ) -&gt; List[User]:\n        \"\"\"\n        Loop through users and execute specified instance method\n\n        Args:\n            users (List[User]): List of User instances\n            method_name (str): Name of a method you want to execute\n            args (List): List of args of the method, they are all related to Network attributes\n\n        Returns:\n            List[User]: List of User instances with executed method\n        \"\"\"\n\n        for user in users:\n            method = getattr(user, method_name)\n            method(*args)\n        return users\n\n    def output_gps(\n        self,\n        users_dictionary: Dict[str, List[User]],\n        gps_output_folder_path: str,\n        partition_columns: Optional[List[str]] = None,\n        existing_data_behavior: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"\n        Write users' synth GPS data with stated output schema for each profile\n\n        Args:\n            users_dictionary (Dict[str, List[User]]): A dictionary where key is a name of a profile and a value is a list of User instances belonging to this profile\n            gps_output_folder_path (str): A path to a folder to store GPS results (created as by appending sub-path to the base/parent path)\n            partition_columns (List[str]): Columsn to use for partitioning\n            existing_data_behavior (str): Controls how the dataset will handle data that already exists in the destination\n        \"\"\"\n\n        self.logger.info(\"Writing GPS data\")\n        gps_data = []\n        gps_data_df = pd.DataFrame(\n            columns=[\n                ColNames.user_id,\n                ColNames.timestamp,\n                ColNames.lon,\n                ColNames.lat,\n                ColNames.profile_name,\n            ]\n        )\n\n        for profile_name, users in users_dictionary.items():\n            for user in users:\n                gps_data += user.data_array\n            gps_data_profile_df = pd.DataFrame(\n                gps_data,\n                columns=[\n                    ColNames.user_id,\n                    ColNames.timestamp,\n                    ColNames.lon,\n                    ColNames.lat,\n                ],\n            ).sort_values(by=[ColNames.user_id, ColNames.timestamp])\n            # pylint: disable=unsupported-assignment-operation\n            gps_data_profile_df[ColNames.profile_name] = profile_name\n\n            # if you borther with pd.concat FutureWarning, here is a solution\n            # https://stackoverflow.com/questions/77254777/alternative-to-concat-of-empty-dataframe-now-that-it-is-being-deprecated\n            gps_data_df = pd.concat(\n                [gps_data_df, gps_data_profile_df], ignore_index=True\n            )\n\n        write_df_to_parquet(\n            gps_data_df,\n            gps_output_folder_path,\n            partition_columns,\n            existing_data_behavior,\n        )\n\n    def output_network_tables(\n        self,\n        network_dictionary: Dict[str, Network],\n        network_output_folder_path: str,\n        partition_columns: List[str],\n        existing_data_behavior: str,\n    ) -&gt; None:\n        \"\"\"\n        Write network data with stated output schema for each profile\n\n        Args:\n            network_dictionary (Dict[str, Network]): A dictionary where key is a name of a profile and a value is an instance of Network belonging to this profile\n            network_output_folder_path (str): A path to a folder to store network data (created as by appending sub-path to the base/parent path)\n            partition_columns (List[str]): Columsn to use for partitioning\n            existing_data_behavior (str): Controls how the dataset will handle data that already exists in the destination\n        \"\"\"\n\n        self.logger.info(\"Writing Network tables\")\n\n        for network_name, network in network_dictionary.items():\n\n            network_gdf = gpd.GeoDataFrame(\n                pd.concat(\n                    [\n                        network.gdf_hw.assign(loc_type=\"hw\"),\n                        network.gdf_event.assign(loc_type=\"event\"),\n                    ],\n                    ignore_index=True,\n                )\n            ).to_crs(4326)\n\n            network_gdf[ColNames.centre_x] = network_gdf[\"geometry\"].x\n            network_gdf[ColNames.centre_y] = network_gdf[\"geometry\"].y\n\n            network_df = network_gdf.drop(\n                columns=[\"nearest_node_id\", \"distance_to_node\", \"geometry\"]\n            )\n\n            network_df[ColNames.network_name] = network_name\n\n            write_df_to_parquet(\n                network_df,\n                network_output_folder_path,\n                partition_columns,\n                existing_data_behavior,\n            )\n\n    def output_metadata(\n        self,\n        users_dictionary: Dict[str, List[User]],\n        network_dictionary: Dict[str, Network],\n        users_network_dict: Dict[str, str],\n        metadata_output_folder_path: str,\n        partition_columns: Optional[List[str]] = None,\n        existing_data_behavior: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"\n        Write metadata with stated output schema for each profile to see anchor locations for every user (e.g. for checking purposes)\n\n        Args:\n            users_dictionary (Dict[str, List[User]]): A dictionary where key is a name of a profile and a value is a list of User instances belonging to this profile\n            network_dictionary (Dict[str, Network]): A dictionary where key is a name of a profile and a value is an instance of Network belonging to this profile\n            users_network_dict (Dict[str, str]): Dictionaru to connect users to their network\n            metadata_output_folder_path (str): A path to a folder to store GPS results (created as by appending sub-path to the base/parent path)\n            partition_columns (List[str]): Columsn to use for partitioning\n            existing_data_behavior (str): Controls how the dataset will handle data that already exists in the destination\n        \"\"\"\n        self.logger.info(\"Writing metadata\\n\")\n\n        for profile_name, users in users_dictionary.items():\n\n            network_name = users_network_dict[profile_name]\n\n            network = network_dictionary[network_name]\n\n            # network_name is needed to make it clear in what particular network to search for locations by ids\n            # alternatice way is to look in config\n            metadata_data_df = pd.DataFrame(\n                [\n                    [\n                        user.user_id,\n                        network.gdf_hw.iloc[user.home_id][\"osmid\"],\n                        network.gdf_hw.iloc[user.work_id][\"osmid\"],\n                        network.gdf_event.iloc[user.regular_loc_array][\"osmid\"].values,\n                        profile_name,\n                        network_name,\n                    ]\n                    for user in users\n                ],\n                columns=[\n                    ColNames.user_id,\n                    ColNames.home_id,\n                    ColNames.work_id,\n                    ColNames.regular_loc_array,\n                    ColNames.profile_name,\n                    ColNames.network_name,\n                ],\n            )\n\n            write_df_to_parquet(\n                metadata_data_df,\n                metadata_output_folder_path,\n                partition_columns,\n                existing_data_behavior,\n            )\n\n    def run(self):\n        # pylint: disable=missing-function-docstring\n        profiles = self.config[\"PROFILES\"].keys()\n\n        # for each profile\n        for profile in profiles:\n            # get config params\n            profile_config = self.config[\"PROFILES\"][profile]\n            # and profile name\n            profile_name = profile_config[\"PROFILE_NAME\"]\n\n            self.logger.info(\"Started generating process for profile: %s\", profile_name)\n\n            profile_network_config = profile_config[\"NETWORK_PARAMS\"]\n\n            # check if a network was already created (some profile scan have identical network\n            if profile_network_config[\"USE_ALREADY_CREATED\"] is True:\n                # reuse already created network\n                try:\n                    network = self.network_dictionary[\n                        profile_network_config[\"NETWORK_NAME\"]\n                    ]\n                except KeyError as e:\n                    self.logger.warning(\n                        \"%s : the network called %s is not yet created\",\n                        e,\n                        profile_network_config[\"NETWORK_NAME\"],\n                    )\n                    raise\n\n            else:\n                # create a unique Network\n                # store Network in a dict\n                network = self.create_network(profile_network_config)\n                self.network_dictionary[profile_network_config[\"NETWORK_NAME\"]] = (\n                    network\n                )\n            self.logger.info(\n                \"Network for profile '%s' is generated, network name: %s\",\n                profile_name,\n                profile_network_config[\"NETWORK_NAME\"],\n            )\n            # store the Network attributes globally so each user instance can access them\n            self.users_network_dict[profile_name] = profile_network_config[\n                \"NETWORK_NAME\"\n            ]\n\n            (\n                network_graph_crs,\n                network_gdf_hw,\n                network_gdf_event,\n                network_graph_proj,\n                network_graph_nodes,\n            ) = (\n                getattr(network, attr)\n                for attr in [\"graph_crs\", \"gdf_hw\", \"gdf_event\", \"graph_proj\", \"nodes\"]\n            )\n            # transformer from graph projection to WGS86\n            transformer_to_WGS = Transformer.from_crs(\n                network_graph_crs, crs_4326, always_xy=True\n            )\n\n            # generagte users of a profile\n            profile_users_config = profile_config[\"USER_PARAMS\"]\n            users = self.generate_users(profile_users_config)\n            self.logger.info(\n                \"Users for profile '%s' is generated, number of users: %s\",\n                profile_name,\n                profile_users_config[\"NUM_USERS\"],\n            )\n            # create meaningful locations for each user\n            users_with_meaningful_loc = self.execute_method_for_users(\n                users,\n                \"get_meaningful_locations\",\n                [\n                    network_gdf_hw,\n                    network_gdf_event,\n                ],\n            )\n            self.logger.info(\n                \"Meaningful locations for users of profile '%s' is generated\",\n                profile_name,\n            )\n            # generate synth gps data for each user\n            users_with_gps = self.execute_method_for_users(\n                users_with_meaningful_loc,\n                \"generate_gps\",\n                [\n                    network_gdf_hw,\n                    network_gdf_event,\n                    network_graph_proj,\n                    network_graph_nodes,\n                    transformer_to_WGS,\n                ],\n            )\n            self.logger.info(\n                \"GPD data for users of profile '%s' is generated\", profile_name\n            )\n            # store users with gps data in a dict\n            self.users_dictionary[profile_name] = users_with_gps\n\n        # Write output results\n        self.logger.info(\"Started writing results\")\n\n        self.output_gps(self.users_dictionary, self.config[\"OUTPUTS\"][\"GPS\"][\"PATH\"])\n        self.output_network_tables(\n            self.network_dictionary,\n            self.config[\"OUTPUTS\"][\"NETWORK_TABLES\"][\"PATH\"],\n            self.config[\"OUTPUTS\"][\"NETWORK_TABLES\"][\"PARTITION_COLUMNS\"],\n            self.config[\"OUTPUTS\"][\"NETWORK_TABLES\"][\"EXISTING_DATA_BEHAVIOUR\"],\n        )\n        self.output_metadata(\n            self.users_dictionary,\n            self.network_dictionary,\n            self.users_network_dict,\n            self.config[\"OUTPUTS\"][\"METADATA\"][\"PATH\"],\n        )\n</code></pre>"},{"location":"reference/gps_generator/gps_generator/#gps_generator.gps_generator.GPS_Generator.create_network","title":"<code>create_network(profile_network_config)</code>","text":"<p>Initialise Network class and run it</p> <p>Parameters:</p> Name Type Description Default <code>profile_network_config</code> <code>Any</code> <p>YAML object with config params regarding network</p> required <p>Returns:</p> Name Type Description <code>Network</code> <code>Network</code> <p>Instance of Network class with completed run method</p> Source code in <code>gps_synth/gps_generator/gps_generator.py</code> <pre><code>def create_network(self, profile_network_config: Any) -&gt; Network:\n    \"\"\"\n    Initialise Network class and run it\n\n    Args:\n        profile_network_config (Any): YAML object with config params regarding network\n\n    Returns:\n        Network: Instance of Network class with completed run method\n    \"\"\"\n\n    network_class = class_getter(\n        profile_network_config[\"NETWORK_MODULE_PATH\"],\n        profile_network_config[\"NETWORK_CLASS\"],\n    )\n\n    network = network_class(profile_network_config)\n\n    network.run()\n\n    return network\n</code></pre>"},{"location":"reference/gps_generator/gps_generator/#gps_generator.gps_generator.GPS_Generator.execute_method_for_users","title":"<code>execute_method_for_users(users, method_name, args=None)</code>","text":"<p>Loop through users and execute specified instance method</p> <p>Parameters:</p> Name Type Description Default <code>users</code> <code>List[User]</code> <p>List of User instances</p> required <code>method_name</code> <code>str</code> <p>Name of a method you want to execute</p> required <code>args</code> <code>List</code> <p>List of args of the method, they are all related to Network attributes</p> <code>None</code> <p>Returns:</p> Type Description <code>List[User]</code> <p>List[User]: List of User instances with executed method</p> Source code in <code>gps_synth/gps_generator/gps_generator.py</code> <pre><code>def execute_method_for_users(\n    self, users: List[User], method_name: str, args: List = None\n) -&gt; List[User]:\n    \"\"\"\n    Loop through users and execute specified instance method\n\n    Args:\n        users (List[User]): List of User instances\n        method_name (str): Name of a method you want to execute\n        args (List): List of args of the method, they are all related to Network attributes\n\n    Returns:\n        List[User]: List of User instances with executed method\n    \"\"\"\n\n    for user in users:\n        method = getattr(user, method_name)\n        method(*args)\n    return users\n</code></pre>"},{"location":"reference/gps_generator/gps_generator/#gps_generator.gps_generator.GPS_Generator.generate_users","title":"<code>generate_users(profile_user_config)</code>","text":"<p>Initialise User class and run it as many times as specified in NUM_USERS config param. Store instances in a list</p> <p>Parameters:</p> Name Type Description Default <code>profile_user_config</code> <code>Any</code> <p>YAML object with config params regarding users</p> required <p>Returns:</p> Type Description <code>List[User]</code> <p>List[User]: list of instances of User class with completed run method</p> Source code in <code>gps_synth/gps_generator/gps_generator.py</code> <pre><code>def generate_users(self, profile_user_config: Any) -&gt; List[User]:\n    \"\"\"\n    Initialise User class and run it as many times as specified in NUM_USERS config param.\n    Store instances in a list\n\n    Args:\n        profile_user_config (Any): YAML object with config params regarding users\n\n    Returns:\n        List[User]: list of instances of User class with completed run method\n    \"\"\"\n    users_array = []\n\n    user_class = class_getter(\n        profile_user_config[\"USER_MODULE_PATH\"], profile_user_config[\"USER_CLASS\"]\n    )\n\n    for _ in range(profile_user_config[\"NUM_USERS\"]):\n        # ensure uniqueness of user ids in case of appending parquets\n        user_id = uuid.uuid4().hex\n        new_user = user_class(user_id, profile_user_config)\n        users_array.append(new_user)\n\n    return users_array\n</code></pre>"},{"location":"reference/gps_generator/gps_generator/#gps_generator.gps_generator.GPS_Generator.output_gps","title":"<code>output_gps(users_dictionary, gps_output_folder_path, partition_columns=None, existing_data_behavior=None)</code>","text":"<p>Write users' synth GPS data with stated output schema for each profile</p> <p>Parameters:</p> Name Type Description Default <code>users_dictionary</code> <code>Dict[str, List[User]]</code> <p>A dictionary where key is a name of a profile and a value is a list of User instances belonging to this profile</p> required <code>gps_output_folder_path</code> <code>str</code> <p>A path to a folder to store GPS results (created as by appending sub-path to the base/parent path)</p> required <code>partition_columns</code> <code>List[str]</code> <p>Columsn to use for partitioning</p> <code>None</code> <code>existing_data_behavior</code> <code>str</code> <p>Controls how the dataset will handle data that already exists in the destination</p> <code>None</code> Source code in <code>gps_synth/gps_generator/gps_generator.py</code> <pre><code>def output_gps(\n    self,\n    users_dictionary: Dict[str, List[User]],\n    gps_output_folder_path: str,\n    partition_columns: Optional[List[str]] = None,\n    existing_data_behavior: Optional[str] = None,\n) -&gt; None:\n    \"\"\"\n    Write users' synth GPS data with stated output schema for each profile\n\n    Args:\n        users_dictionary (Dict[str, List[User]]): A dictionary where key is a name of a profile and a value is a list of User instances belonging to this profile\n        gps_output_folder_path (str): A path to a folder to store GPS results (created as by appending sub-path to the base/parent path)\n        partition_columns (List[str]): Columsn to use for partitioning\n        existing_data_behavior (str): Controls how the dataset will handle data that already exists in the destination\n    \"\"\"\n\n    self.logger.info(\"Writing GPS data\")\n    gps_data = []\n    gps_data_df = pd.DataFrame(\n        columns=[\n            ColNames.user_id,\n            ColNames.timestamp,\n            ColNames.lon,\n            ColNames.lat,\n            ColNames.profile_name,\n        ]\n    )\n\n    for profile_name, users in users_dictionary.items():\n        for user in users:\n            gps_data += user.data_array\n        gps_data_profile_df = pd.DataFrame(\n            gps_data,\n            columns=[\n                ColNames.user_id,\n                ColNames.timestamp,\n                ColNames.lon,\n                ColNames.lat,\n            ],\n        ).sort_values(by=[ColNames.user_id, ColNames.timestamp])\n        # pylint: disable=unsupported-assignment-operation\n        gps_data_profile_df[ColNames.profile_name] = profile_name\n\n        # if you borther with pd.concat FutureWarning, here is a solution\n        # https://stackoverflow.com/questions/77254777/alternative-to-concat-of-empty-dataframe-now-that-it-is-being-deprecated\n        gps_data_df = pd.concat(\n            [gps_data_df, gps_data_profile_df], ignore_index=True\n        )\n\n    write_df_to_parquet(\n        gps_data_df,\n        gps_output_folder_path,\n        partition_columns,\n        existing_data_behavior,\n    )\n</code></pre>"},{"location":"reference/gps_generator/gps_generator/#gps_generator.gps_generator.GPS_Generator.output_metadata","title":"<code>output_metadata(users_dictionary, network_dictionary, users_network_dict, metadata_output_folder_path, partition_columns=None, existing_data_behavior=None)</code>","text":"<p>Write metadata with stated output schema for each profile to see anchor locations for every user (e.g. for checking purposes)</p> <p>Parameters:</p> Name Type Description Default <code>users_dictionary</code> <code>Dict[str, List[User]]</code> <p>A dictionary where key is a name of a profile and a value is a list of User instances belonging to this profile</p> required <code>network_dictionary</code> <code>Dict[str, Network]</code> <p>A dictionary where key is a name of a profile and a value is an instance of Network belonging to this profile</p> required <code>users_network_dict</code> <code>Dict[str, str]</code> <p>Dictionaru to connect users to their network</p> required <code>metadata_output_folder_path</code> <code>str</code> <p>A path to a folder to store GPS results (created as by appending sub-path to the base/parent path)</p> required <code>partition_columns</code> <code>List[str]</code> <p>Columsn to use for partitioning</p> <code>None</code> <code>existing_data_behavior</code> <code>str</code> <p>Controls how the dataset will handle data that already exists in the destination</p> <code>None</code> Source code in <code>gps_synth/gps_generator/gps_generator.py</code> <pre><code>def output_metadata(\n    self,\n    users_dictionary: Dict[str, List[User]],\n    network_dictionary: Dict[str, Network],\n    users_network_dict: Dict[str, str],\n    metadata_output_folder_path: str,\n    partition_columns: Optional[List[str]] = None,\n    existing_data_behavior: Optional[str] = None,\n) -&gt; None:\n    \"\"\"\n    Write metadata with stated output schema for each profile to see anchor locations for every user (e.g. for checking purposes)\n\n    Args:\n        users_dictionary (Dict[str, List[User]]): A dictionary where key is a name of a profile and a value is a list of User instances belonging to this profile\n        network_dictionary (Dict[str, Network]): A dictionary where key is a name of a profile and a value is an instance of Network belonging to this profile\n        users_network_dict (Dict[str, str]): Dictionaru to connect users to their network\n        metadata_output_folder_path (str): A path to a folder to store GPS results (created as by appending sub-path to the base/parent path)\n        partition_columns (List[str]): Columsn to use for partitioning\n        existing_data_behavior (str): Controls how the dataset will handle data that already exists in the destination\n    \"\"\"\n    self.logger.info(\"Writing metadata\\n\")\n\n    for profile_name, users in users_dictionary.items():\n\n        network_name = users_network_dict[profile_name]\n\n        network = network_dictionary[network_name]\n\n        # network_name is needed to make it clear in what particular network to search for locations by ids\n        # alternatice way is to look in config\n        metadata_data_df = pd.DataFrame(\n            [\n                [\n                    user.user_id,\n                    network.gdf_hw.iloc[user.home_id][\"osmid\"],\n                    network.gdf_hw.iloc[user.work_id][\"osmid\"],\n                    network.gdf_event.iloc[user.regular_loc_array][\"osmid\"].values,\n                    profile_name,\n                    network_name,\n                ]\n                for user in users\n            ],\n            columns=[\n                ColNames.user_id,\n                ColNames.home_id,\n                ColNames.work_id,\n                ColNames.regular_loc_array,\n                ColNames.profile_name,\n                ColNames.network_name,\n            ],\n        )\n\n        write_df_to_parquet(\n            metadata_data_df,\n            metadata_output_folder_path,\n            partition_columns,\n            existing_data_behavior,\n        )\n</code></pre>"},{"location":"reference/gps_generator/gps_generator/#gps_generator.gps_generator.GPS_Generator.output_network_tables","title":"<code>output_network_tables(network_dictionary, network_output_folder_path, partition_columns, existing_data_behavior)</code>","text":"<p>Write network data with stated output schema for each profile</p> <p>Parameters:</p> Name Type Description Default <code>network_dictionary</code> <code>Dict[str, Network]</code> <p>A dictionary where key is a name of a profile and a value is an instance of Network belonging to this profile</p> required <code>network_output_folder_path</code> <code>str</code> <p>A path to a folder to store network data (created as by appending sub-path to the base/parent path)</p> required <code>partition_columns</code> <code>List[str]</code> <p>Columsn to use for partitioning</p> required <code>existing_data_behavior</code> <code>str</code> <p>Controls how the dataset will handle data that already exists in the destination</p> required Source code in <code>gps_synth/gps_generator/gps_generator.py</code> <pre><code>def output_network_tables(\n    self,\n    network_dictionary: Dict[str, Network],\n    network_output_folder_path: str,\n    partition_columns: List[str],\n    existing_data_behavior: str,\n) -&gt; None:\n    \"\"\"\n    Write network data with stated output schema for each profile\n\n    Args:\n        network_dictionary (Dict[str, Network]): A dictionary where key is a name of a profile and a value is an instance of Network belonging to this profile\n        network_output_folder_path (str): A path to a folder to store network data (created as by appending sub-path to the base/parent path)\n        partition_columns (List[str]): Columsn to use for partitioning\n        existing_data_behavior (str): Controls how the dataset will handle data that already exists in the destination\n    \"\"\"\n\n    self.logger.info(\"Writing Network tables\")\n\n    for network_name, network in network_dictionary.items():\n\n        network_gdf = gpd.GeoDataFrame(\n            pd.concat(\n                [\n                    network.gdf_hw.assign(loc_type=\"hw\"),\n                    network.gdf_event.assign(loc_type=\"event\"),\n                ],\n                ignore_index=True,\n            )\n        ).to_crs(4326)\n\n        network_gdf[ColNames.centre_x] = network_gdf[\"geometry\"].x\n        network_gdf[ColNames.centre_y] = network_gdf[\"geometry\"].y\n\n        network_df = network_gdf.drop(\n            columns=[\"nearest_node_id\", \"distance_to_node\", \"geometry\"]\n        )\n\n        network_df[ColNames.network_name] = network_name\n\n        write_df_to_parquet(\n            network_df,\n            network_output_folder_path,\n            partition_columns,\n            existing_data_behavior,\n        )\n</code></pre>"},{"location":"reference/network/","title":"network","text":""},{"location":"reference/network/network/","title":"network","text":""},{"location":"reference/network/network/#network.network.Network","title":"<code>Network</code>","text":"Source code in <code>gps_synth/network/network.py</code> <pre><code>class Network:\n    def __init__(self, profile_network_config):\n        self.network_name = profile_network_config[\"NETWORK_NAME\"]\n        self.place_name = profile_network_config[\"PLACE_NAME\"]\n        self.network_type = profile_network_config[\"NETWORK_TYPE\"]\n        self.osm_tags_for_hw = profile_network_config[\"OSM_TAGS_FOR_HOME_AND_WORK\"]\n        self.osm_tags_for_event = profile_network_config[\"OSM_TAGS_FOR_EVENT\"]\n\n        self.graph_proj = None\n        self.graph_crs = None\n        self.nodes = None\n\n        self.gdf_hw = None\n        self.gdf_event = None\n\n    def prepare_graph(self, place_name: str, network_type: str) -&gt; None:\n        \"\"\"\n        Prepare all needed graph's features to properly create movements along this graph\n        and store them in instance attributes of a Network class\n\n        Args:\n            place_name (str): A name of place in which a graph should be derived\n            network_type (str): What type of street network to get if custom_filter is None\n        \"\"\"\n        graph = ox.graph_from_place(place_name, network_type=network_type)\n        graph_proj = ox.project_graph(graph)\n        nodes = ox.graph_to_gdfs(graph_proj, nodes=True, edges=False)\n        graph_crs = nodes.crs\n\n        self.graph_proj = graph_proj\n        self.graph_crs = graph_crs\n        self.nodes = nodes\n\n    def create_locations(\n        self,\n        place_name: str,\n        osm_tags_for_hw: List[str],\n        osm_tags_for_event: List[str],\n        graph_proj: MultiDiGraph,\n        graph_crs: int,\n    ) -&gt; DataFrame:\n        \"\"\"\n        Derive OSM locations based on specified tags, leave only those that have geometry,\n        derived centorid of the locations (since some of them could be not a Point but Polygon/MultiPolygon),\n        find nearest network's node to a locationa and calculates distance to it (some locations can be quite far from network)\n\n        Args:\n            place_name (str): A name of place in which OSM locations should be derived\n            osm_tags_for_hw (List[str]): List of OSM tags to use for search location of home/work anchor points\n            osm_tags_for_event (List[str]): List of OSM tags to use for search location of event anchor points\n            graph_proj (MultiDiGraph): A graph with nodes and edges\n            graph_crs (int): EPSG of a graph's CRS\n\n        Returns:\n            Dataframe: All locations from OSM filtered by tag and geometry coditions, and with several new computed columns\n        \"\"\"\n        combined_osm_tags = osm_tags_for_hw + osm_tags_for_event\n        gdf_locations = ox.features_from_place(\n            place_name, tags=dict.fromkeys(combined_osm_tags, True)\n        )\n        geometry_condition = ~(\n            gdf_locations[\"geometry\"].isna() | gdf_locations[\"geometry\"].empty\n        )\n        columns_to_save = [\"name\", \"geometry\"] + combined_osm_tags\n\n        gdf_locations = gdf_locations[geometry_condition][columns_to_save].to_crs(\n            graph_crs\n        )\n        gdf_locations[\"geometry\"] = gdf_locations[\"geometry\"].centroid\n        gdf_locations[\"nearest_node_id\"], gdf_locations[\"distance_to_node\"] = (\n            ox.distance.nearest_nodes(\n                graph_proj,\n                gdf_locations[\"geometry\"].x,\n                gdf_locations[\"geometry\"].y,\n                return_dist=True,\n            )\n        )\n\n        return gdf_locations\n\n    def get_specific_type_of_locations(\n        self,\n        df_locations: DataFrame,\n        filter_columns: List[str],\n        delete_columns: List[str],\n    ) -&gt; DataFrame:\n        \"\"\"\n        Take location dataframe and filtered it by the condition that there should be at least one not null value\n        in tag columns connected to some anchor point and then delete all unnecessary columns (columns with tag information)\n\n        Args:\n            df_locations (DataFrame): All locations to be used for anchor points of users\n            filter_columns (List[str]): List of OSM tags (and also column names) to check for nulls\n            delete_columns (List[str]): List of OSM tags (and also column names) to delete after filtering\n\n        Returns:\n            DataFrame: Filtered locations dataframe\n        \"\"\"\n\n        return df_locations[df_locations[filter_columns].notnull().any(axis=1)][\n            list(set(df_locations.columns) - set(delete_columns))\n        ].reset_index()\n\n    def run(self):\n        # pylint: disable=missing-function-docstring\n        # prepare graph and enrich instance attributes\n        self.prepare_graph(self.place_name, self.network_type)\n        # create location for anchor points\n        gdf_locations = self.create_locations(\n            self.place_name,\n            self.osm_tags_for_hw,\n            self.osm_tags_for_event,\n            self.graph_proj,\n            self.graph_crs,\n        )\n\n        filter_columns_hw = self.osm_tags_for_hw\n        filter_columns_event = self.osm_tags_for_event\n\n        delete_columns = filter_columns_hw + filter_columns_event\n\n        # filter locations for home and work anchor points and store in df_hw attribute\n        self.gdf_hw = self.get_specific_type_of_locations(\n            gdf_locations, filter_columns_hw, delete_columns\n        )\n        # filter locations for event anchor points and store in df_event attribute\n        self.gdf_event = self.get_specific_type_of_locations(\n            gdf_locations, filter_columns_event, delete_columns\n        )\n\n        del gdf_locations\n</code></pre>"},{"location":"reference/network/network/#network.network.Network.create_locations","title":"<code>create_locations(place_name, osm_tags_for_hw, osm_tags_for_event, graph_proj, graph_crs)</code>","text":"<p>Derive OSM locations based on specified tags, leave only those that have geometry, derived centorid of the locations (since some of them could be not a Point but Polygon/MultiPolygon), find nearest network's node to a locationa and calculates distance to it (some locations can be quite far from network)</p> <p>Parameters:</p> Name Type Description Default <code>place_name</code> <code>str</code> <p>A name of place in which OSM locations should be derived</p> required <code>osm_tags_for_hw</code> <code>List[str]</code> <p>List of OSM tags to use for search location of home/work anchor points</p> required <code>osm_tags_for_event</code> <code>List[str]</code> <p>List of OSM tags to use for search location of event anchor points</p> required <code>graph_proj</code> <code>MultiDiGraph</code> <p>A graph with nodes and edges</p> required <code>graph_crs</code> <code>int</code> <p>EPSG of a graph's CRS</p> required <p>Returns:</p> Name Type Description <code>Dataframe</code> <code>DataFrame</code> <p>All locations from OSM filtered by tag and geometry coditions, and with several new computed columns</p> Source code in <code>gps_synth/network/network.py</code> <pre><code>def create_locations(\n    self,\n    place_name: str,\n    osm_tags_for_hw: List[str],\n    osm_tags_for_event: List[str],\n    graph_proj: MultiDiGraph,\n    graph_crs: int,\n) -&gt; DataFrame:\n    \"\"\"\n    Derive OSM locations based on specified tags, leave only those that have geometry,\n    derived centorid of the locations (since some of them could be not a Point but Polygon/MultiPolygon),\n    find nearest network's node to a locationa and calculates distance to it (some locations can be quite far from network)\n\n    Args:\n        place_name (str): A name of place in which OSM locations should be derived\n        osm_tags_for_hw (List[str]): List of OSM tags to use for search location of home/work anchor points\n        osm_tags_for_event (List[str]): List of OSM tags to use for search location of event anchor points\n        graph_proj (MultiDiGraph): A graph with nodes and edges\n        graph_crs (int): EPSG of a graph's CRS\n\n    Returns:\n        Dataframe: All locations from OSM filtered by tag and geometry coditions, and with several new computed columns\n    \"\"\"\n    combined_osm_tags = osm_tags_for_hw + osm_tags_for_event\n    gdf_locations = ox.features_from_place(\n        place_name, tags=dict.fromkeys(combined_osm_tags, True)\n    )\n    geometry_condition = ~(\n        gdf_locations[\"geometry\"].isna() | gdf_locations[\"geometry\"].empty\n    )\n    columns_to_save = [\"name\", \"geometry\"] + combined_osm_tags\n\n    gdf_locations = gdf_locations[geometry_condition][columns_to_save].to_crs(\n        graph_crs\n    )\n    gdf_locations[\"geometry\"] = gdf_locations[\"geometry\"].centroid\n    gdf_locations[\"nearest_node_id\"], gdf_locations[\"distance_to_node\"] = (\n        ox.distance.nearest_nodes(\n            graph_proj,\n            gdf_locations[\"geometry\"].x,\n            gdf_locations[\"geometry\"].y,\n            return_dist=True,\n        )\n    )\n\n    return gdf_locations\n</code></pre>"},{"location":"reference/network/network/#network.network.Network.get_specific_type_of_locations","title":"<code>get_specific_type_of_locations(df_locations, filter_columns, delete_columns)</code>","text":"<p>Take location dataframe and filtered it by the condition that there should be at least one not null value in tag columns connected to some anchor point and then delete all unnecessary columns (columns with tag information)</p> <p>Parameters:</p> Name Type Description Default <code>df_locations</code> <code>DataFrame</code> <p>All locations to be used for anchor points of users</p> required <code>filter_columns</code> <code>List[str]</code> <p>List of OSM tags (and also column names) to check for nulls</p> required <code>delete_columns</code> <code>List[str]</code> <p>List of OSM tags (and also column names) to delete after filtering</p> required <p>Returns:</p> Name Type Description <code>DataFrame</code> <code>DataFrame</code> <p>Filtered locations dataframe</p> Source code in <code>gps_synth/network/network.py</code> <pre><code>def get_specific_type_of_locations(\n    self,\n    df_locations: DataFrame,\n    filter_columns: List[str],\n    delete_columns: List[str],\n) -&gt; DataFrame:\n    \"\"\"\n    Take location dataframe and filtered it by the condition that there should be at least one not null value\n    in tag columns connected to some anchor point and then delete all unnecessary columns (columns with tag information)\n\n    Args:\n        df_locations (DataFrame): All locations to be used for anchor points of users\n        filter_columns (List[str]): List of OSM tags (and also column names) to check for nulls\n        delete_columns (List[str]): List of OSM tags (and also column names) to delete after filtering\n\n    Returns:\n        DataFrame: Filtered locations dataframe\n    \"\"\"\n\n    return df_locations[df_locations[filter_columns].notnull().any(axis=1)][\n        list(set(df_locations.columns) - set(delete_columns))\n    ].reset_index()\n</code></pre>"},{"location":"reference/network/network/#network.network.Network.prepare_graph","title":"<code>prepare_graph(place_name, network_type)</code>","text":"<p>Prepare all needed graph's features to properly create movements along this graph and store them in instance attributes of a Network class</p> <p>Parameters:</p> Name Type Description Default <code>place_name</code> <code>str</code> <p>A name of place in which a graph should be derived</p> required <code>network_type</code> <code>str</code> <p>What type of street network to get if custom_filter is None</p> required Source code in <code>gps_synth/network/network.py</code> <pre><code>def prepare_graph(self, place_name: str, network_type: str) -&gt; None:\n    \"\"\"\n    Prepare all needed graph's features to properly create movements along this graph\n    and store them in instance attributes of a Network class\n\n    Args:\n        place_name (str): A name of place in which a graph should be derived\n        network_type (str): What type of street network to get if custom_filter is None\n    \"\"\"\n    graph = ox.graph_from_place(place_name, network_type=network_type)\n    graph_proj = ox.project_graph(graph)\n    nodes = ox.graph_to_gdfs(graph_proj, nodes=True, edges=False)\n    graph_crs = nodes.crs\n\n    self.graph_proj = graph_proj\n    self.graph_crs = graph_crs\n    self.nodes = nodes\n</code></pre>"},{"location":"reference/user/","title":"user","text":""},{"location":"reference/user/user_employed_walk/","title":"user_employed_walk","text":""},{"location":"reference/user/user_employed_walk/#user.user_employed_walk.User_employed_walk","title":"<code>User_employed_walk</code>","text":"<p>               Bases: <code>User</code></p> Source code in <code>gps_synth/user/user_employed_walk.py</code> <pre><code>class User_employed_walk(User):\n    def __init__(self, user_id: int, profile_user_config):\n        super().__init__(user_id, profile_user_config)\n        self.child_class_name = \"User_walk\"\n\n    def random_plot_of_day(\n        self,\n        time_start: Timestamp,\n        beggining_of_day: Timestamp,\n        day_of_week: int,\n        list_of_locations: List[List[Union[int, float]]],\n        network_graph_proj,\n        network_nodes,\n        transformer_to_WGS,\n    ) -&gt; Timestamp:\n        \"\"\"\n        Create GPS data for a day following to some extend a random plot (there are some rules, e.g. on weekends\n        user can stay at home longer than at work days) but time boundaries vary. Store result users' data_array attribute\n\n        Args:\n            time_start (Timestamp): Timestamp from which to start generating GPS data for a day\n            beggining_of_day (Timestamp): Conventional timestamp of day beggining (e.g. 10.12.2023 00:00:00),\n                                          needed to create \"absolute\" boundaries of some activities\n            day_of_week (int): _description_\n            list_of_locations (List[List[Union[int, float]]])): List of lists, each element has three items:\n                                                                nearest node id and lat and lon coordinates of location's centroid\n\n        Returns:\n            Timestamp: Time from which to start generating GPS data for the next day\n\n        \"\"\"\n\n        i = 0\n        final_timestamp = None\n\n        # if it is weekends and the number of locations to visit/stay is more than 1 (some events apart from home)\n        # stay at home till 10-14 p.m.\n        if day_of_week &gt;= 6 and len(list_of_locations) &gt; 1:\n\n            stay_activity_time = super().get_static_points(\n                self.user_id,\n                self.data_array,\n                transformer_to_WGS,\n                list_of_locations[i][1],\n                list_of_locations[i][2],\n                time_start,\n                beggining_of_day + timedelta(hours=random.randint(10, 14)),\n            )\n        # if it is a weekday\n        elif day_of_week &lt; 6:\n            # stay at home between 7-9 p.m.\n            stay_activity_time = super().get_static_points(\n                self.user_id,\n                self.data_array,\n                transformer_to_WGS,\n                list_of_locations[i][1],\n                list_of_locations[i][2],\n                time_start,\n                beggining_of_day + timedelta(hours=random.randint(7, 9)),\n            )\n            # go to work\n            moving_activity_time = super().get_moving_points(\n                self.user_id,\n                self.data_array,\n                network_graph_proj,\n                network_nodes,\n                transformer_to_WGS,\n                list_of_locations[i][0],\n                list_of_locations[i + 1][0],\n                (list_of_locations[i][1], list_of_locations[i][2]),\n                (list_of_locations[i + 1][1], list_of_locations[i + 1][2]),\n                self.mean_move_speed_ms,\n                self.proximity_to_road,\n                stay_activity_time,\n            )\n            # stay at work till 17-19 p.m.\n            stay_activity_time = super().get_static_points(\n                self.user_id,\n                self.data_array,\n                transformer_to_WGS,\n                list_of_locations[i + 1][1],\n                list_of_locations[i + 1][2],\n                moving_activity_time,\n                beggining_of_day + timedelta(hours=random.randint(17, 19)),\n            )\n\n            i += 1\n\n        else:\n            # it is a weekedn and a user decided to stay at home whole day\n            # poor they\n            stay_activity_time = super().get_static_points(\n                self.user_id,\n                self.data_array,\n                transformer_to_WGS,\n                list_of_locations[i][1],\n                list_of_locations[i][2],\n                time_start,\n                beggining_of_day + timedelta(hours=random.randint(22, 26)),\n            )\n\n            # day is finished\n            final_timestamp = stay_activity_time\n\n        # if there are some event locatiions to visit\n        while i &lt; (len(list_of_locations) - 1):\n            # first move to this event location\n            moving_activity_time = super().get_moving_points(\n                self.user_id,\n                self.data_array,\n                network_graph_proj,\n                network_nodes,\n                transformer_to_WGS,\n                list_of_locations[i][0],\n                list_of_locations[i + 1][0],\n                (list_of_locations[i][1], list_of_locations[i][2]),\n                (list_of_locations[i + 1][1], list_of_locations[i + 1][2]),\n                self.mean_move_speed_ms,\n                self.proximity_to_road,\n                time_start=stay_activity_time,\n            )\n            # stay at event location between 1-3 hours\n            stay_activity_time = super().get_static_points(\n                self.user_id,\n                self.data_array,\n                transformer_to_WGS,\n                list_of_locations[i + 1][1],\n                list_of_locations[i + 1][2],\n                moving_activity_time,\n                moving_activity_time + timedelta(hours=random.randint(1, 3)),\n            )\n            # repeat the process till the last event location\n            i += 1\n\n        # finally move to home\n        # this condition is needed to handle situation when a user decieds to stay at home whole day (i=0)\n        # no need to move from home to home\n        if i &gt; 0:\n\n            moving_activity_time = super().get_moving_points(\n                self.user_id,\n                self.data_array,\n                network_graph_proj,\n                network_nodes,\n                transformer_to_WGS,\n                list_of_locations[i][0],\n                list_of_locations[0][0],\n                (list_of_locations[i][1], list_of_locations[i][2]),\n                (list_of_locations[0][1], list_of_locations[0][2]),\n                self.mean_move_speed_ms,\n                self.proximity_to_road,\n                stay_activity_time,\n            )\n            # day is finished\n            final_timestamp = moving_activity_time\n\n        return final_timestamp\n\n    # kind of run method but with understandable naming\n    def generate_gps(\n        self,\n        network_gdf_hw: GeoDataFrame,\n        network_gdf_event: GeoDataFrame,\n        network_graph_proj: MultiDiGraph,\n        network_nodes: GeoDataFrame,\n        transformer_to_WGS: Transformer,\n    ):\n        # start time of generating GPS data for whole date range of a user\n        time_start = self.date_range[0]\n        # for each day of specified date range of a user\n        for i, _ in enumerate(self.date_range):\n            day = self.date_range[i]\n            day_of_week = day.isoweekday()\n\n            list_of_locations = super().create_list_of_locations(\n                network_gdf_hw,\n                network_gdf_event,\n                self.home_id,\n                self.work_id,\n                self.regular_loc_array,\n                day_of_week,\n            )\n\n            time_start = self.random_plot_of_day(\n                time_start,\n                day,\n                day_of_week,\n                list_of_locations,\n                network_graph_proj,\n                network_nodes,\n                transformer_to_WGS,\n            )\n</code></pre>"},{"location":"reference/user/user_employed_walk/#user.user_employed_walk.User_employed_walk.random_plot_of_day","title":"<code>random_plot_of_day(time_start, beggining_of_day, day_of_week, list_of_locations, network_graph_proj, network_nodes, transformer_to_WGS)</code>","text":"<p>Create GPS data for a day following to some extend a random plot (there are some rules, e.g. on weekends user can stay at home longer than at work days) but time boundaries vary. Store result users' data_array attribute</p> <p>Parameters:</p> Name Type Description Default <code>time_start</code> <code>Timestamp</code> <p>Timestamp from which to start generating GPS data for a day</p> required <code>beggining_of_day</code> <code>Timestamp</code> <p>Conventional timestamp of day beggining (e.g. 10.12.2023 00:00:00),                           needed to create \"absolute\" boundaries of some activities</p> required <code>day_of_week</code> <code>int</code> <p>description</p> required <code>list_of_locations</code> <code>List[List[Union[int, float]]]</code> <p>List of lists, each element has three items:                                                 nearest node id and lat and lon coordinates of location's centroid</p> required <p>Returns:</p> Name Type Description <code>Timestamp</code> <code>Timestamp</code> <p>Time from which to start generating GPS data for the next day</p> Source code in <code>gps_synth/user/user_employed_walk.py</code> <pre><code>def random_plot_of_day(\n    self,\n    time_start: Timestamp,\n    beggining_of_day: Timestamp,\n    day_of_week: int,\n    list_of_locations: List[List[Union[int, float]]],\n    network_graph_proj,\n    network_nodes,\n    transformer_to_WGS,\n) -&gt; Timestamp:\n    \"\"\"\n    Create GPS data for a day following to some extend a random plot (there are some rules, e.g. on weekends\n    user can stay at home longer than at work days) but time boundaries vary. Store result users' data_array attribute\n\n    Args:\n        time_start (Timestamp): Timestamp from which to start generating GPS data for a day\n        beggining_of_day (Timestamp): Conventional timestamp of day beggining (e.g. 10.12.2023 00:00:00),\n                                      needed to create \"absolute\" boundaries of some activities\n        day_of_week (int): _description_\n        list_of_locations (List[List[Union[int, float]]])): List of lists, each element has three items:\n                                                            nearest node id and lat and lon coordinates of location's centroid\n\n    Returns:\n        Timestamp: Time from which to start generating GPS data for the next day\n\n    \"\"\"\n\n    i = 0\n    final_timestamp = None\n\n    # if it is weekends and the number of locations to visit/stay is more than 1 (some events apart from home)\n    # stay at home till 10-14 p.m.\n    if day_of_week &gt;= 6 and len(list_of_locations) &gt; 1:\n\n        stay_activity_time = super().get_static_points(\n            self.user_id,\n            self.data_array,\n            transformer_to_WGS,\n            list_of_locations[i][1],\n            list_of_locations[i][2],\n            time_start,\n            beggining_of_day + timedelta(hours=random.randint(10, 14)),\n        )\n    # if it is a weekday\n    elif day_of_week &lt; 6:\n        # stay at home between 7-9 p.m.\n        stay_activity_time = super().get_static_points(\n            self.user_id,\n            self.data_array,\n            transformer_to_WGS,\n            list_of_locations[i][1],\n            list_of_locations[i][2],\n            time_start,\n            beggining_of_day + timedelta(hours=random.randint(7, 9)),\n        )\n        # go to work\n        moving_activity_time = super().get_moving_points(\n            self.user_id,\n            self.data_array,\n            network_graph_proj,\n            network_nodes,\n            transformer_to_WGS,\n            list_of_locations[i][0],\n            list_of_locations[i + 1][0],\n            (list_of_locations[i][1], list_of_locations[i][2]),\n            (list_of_locations[i + 1][1], list_of_locations[i + 1][2]),\n            self.mean_move_speed_ms,\n            self.proximity_to_road,\n            stay_activity_time,\n        )\n        # stay at work till 17-19 p.m.\n        stay_activity_time = super().get_static_points(\n            self.user_id,\n            self.data_array,\n            transformer_to_WGS,\n            list_of_locations[i + 1][1],\n            list_of_locations[i + 1][2],\n            moving_activity_time,\n            beggining_of_day + timedelta(hours=random.randint(17, 19)),\n        )\n\n        i += 1\n\n    else:\n        # it is a weekedn and a user decided to stay at home whole day\n        # poor they\n        stay_activity_time = super().get_static_points(\n            self.user_id,\n            self.data_array,\n            transformer_to_WGS,\n            list_of_locations[i][1],\n            list_of_locations[i][2],\n            time_start,\n            beggining_of_day + timedelta(hours=random.randint(22, 26)),\n        )\n\n        # day is finished\n        final_timestamp = stay_activity_time\n\n    # if there are some event locatiions to visit\n    while i &lt; (len(list_of_locations) - 1):\n        # first move to this event location\n        moving_activity_time = super().get_moving_points(\n            self.user_id,\n            self.data_array,\n            network_graph_proj,\n            network_nodes,\n            transformer_to_WGS,\n            list_of_locations[i][0],\n            list_of_locations[i + 1][0],\n            (list_of_locations[i][1], list_of_locations[i][2]),\n            (list_of_locations[i + 1][1], list_of_locations[i + 1][2]),\n            self.mean_move_speed_ms,\n            self.proximity_to_road,\n            time_start=stay_activity_time,\n        )\n        # stay at event location between 1-3 hours\n        stay_activity_time = super().get_static_points(\n            self.user_id,\n            self.data_array,\n            transformer_to_WGS,\n            list_of_locations[i + 1][1],\n            list_of_locations[i + 1][2],\n            moving_activity_time,\n            moving_activity_time + timedelta(hours=random.randint(1, 3)),\n        )\n        # repeat the process till the last event location\n        i += 1\n\n    # finally move to home\n    # this condition is needed to handle situation when a user decieds to stay at home whole day (i=0)\n    # no need to move from home to home\n    if i &gt; 0:\n\n        moving_activity_time = super().get_moving_points(\n            self.user_id,\n            self.data_array,\n            network_graph_proj,\n            network_nodes,\n            transformer_to_WGS,\n            list_of_locations[i][0],\n            list_of_locations[0][0],\n            (list_of_locations[i][1], list_of_locations[i][2]),\n            (list_of_locations[0][1], list_of_locations[0][2]),\n            self.mean_move_speed_ms,\n            self.proximity_to_road,\n            stay_activity_time,\n        )\n        # day is finished\n        final_timestamp = moving_activity_time\n\n    return final_timestamp\n</code></pre>"}]}